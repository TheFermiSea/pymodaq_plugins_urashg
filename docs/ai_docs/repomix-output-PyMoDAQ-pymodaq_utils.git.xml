This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where content has been compressed (code blocks are separated by ⋮---- delimiter), security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Content has been compressed - code blocks are separated by ⋮---- delimiter
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  ISSUE_TEMPLATE/
    bug_report.md
    feature_request.md
  workflows/
    python-publish.yml
    tests.yml
    updater.yml
src/
  pymodaq_utils/
    resources/
      config_template.toml
      hatch_build_plugins.py
    serialize/
      factory.py
      mysocket.py
      serializer_legacy.py
      serializer.py
      utils.py
    __init__.py
    abstract.py
    array_manipulation.py
    config.py
    enums.py
    environment.py
    factory.py
    logger.py
    math_utils.py
    mysocket.py
    units.py
    utils.py
    warnings.py
tests/
  data/
    config_template.toml
  serialize/
    ser_utils_test.py
    serializer_legacy_test.py
    serializer_test.py
    socket_test.py
  abstract_test.py
  array_manipulation_test.py
  config_test.py
  enums_test.py
  environment_test.py
  logger_test.py
  math_utils_test.py
  units_test.py
  utils_test.py
.gitattributes
.gitignore
CITATION.cff
LICENSE
MANIFEST.in
pyproject.toml
README.rst
readthedocs.yml
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/ISSUE_TEMPLATE/bug_report.md">
---
name: Bug report
about: Create a report to help us improve
title: ''
labels: ''
assignees: ''

---

**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Browser [e.g. chrome, safari]
 - Version [e.g. 22]

**Smartphone (please complete the following information):**
 - Device: [e.g. iPhone6]
 - OS: [e.g. iOS8.1]
 - Browser [e.g. stock browser, safari]
 - Version [e.g. 22]

**Additional context**
Add any other context about the problem here.
</file>

<file path=".github/ISSUE_TEMPLATE/feature_request.md">
---
name: Feature request
about: Suggest an idea for this project
title: ''
labels: ''
assignees: ''

---

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.
</file>

<file path=".github/workflows/python-publish.yml">
# This workflow will upload a Python Package using Twine when a release is created
# For more information see: https://help.github.com/en/actions/language-and-framework-guides/using-python-with-github-actions#publishing-to-package-registries

name: Upload Python Package

on:
  release:
    types: [created]

jobs:
  build:

    runs-on: ubuntu-latest
          
    steps:
    - uses: actions/checkout@v4.2.2
    - name: Set up Python
      uses: actions/setup-python@v5.6.0
      with:
        python-version: '3.11'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install hatch hatchling
    - name: Build
      run: hatch build
    - name: publish
      env:
        HATCH_INDEX_USER: ${{ secrets.PYPI_USERNAME }}
        HATCH_INDEX_AUTH: ${{ secrets.PYPI_PASSWORD }}
      run: |
        hatch publish
</file>

<file path=".github/workflows/tests.yml">
name: tests

on:
  workflow_call:
  
  pull_request:

  push:
    branches:
    - '*'
    - '!badges' # to exclude execution if someone pushes on this branch (shouldn't happen)

concurrency:
  # github.workflow: name of the workflow
  # github.event.pull_request.number || github.ref: pull request number or branch name if not a pull request
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  # Cancel in-progress runs when a new workflow with the same group name is triggered
  cancel-in-progress: true

jobs:
  tests:
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest", "windows-latest"]
        python-version: ["3.9", "3.10", "3.11", "3.12"]
    runs-on: ${{ matrix.os }}

    steps:     
      # Get the branch name for the badge generation
      - name: Extract branch name
        shell: bash
        run: echo "branch=${GITHUB_REF#refs/heads/}" >> "${GITHUB_OUTPUT}"
        id: extract_branch
        

      - name: Checkout the repo
        uses: actions/checkout@v4.2.2
 
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5.6.0
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest pytest-cov pytest-xdist wheel numpy h5py
          pip install -e .    
      
      # Create folder and set permissions on Ubuntu
      - name: Create local pymodaq folder (Ubuntu)
        if: runner.os == 'Linux'
        run: |
          sudo mkdir -p /etc/.pymodaq
          sudo chmod uo+rw /etc/.pymodaq

      - name: Linting with flake8
        run: |
          # stop the build if there are Python syntax errors or undefined names
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics --exclude=docs
      - name: Tests with ${{ matrix.os }} ${{ matrix.python-version }}
        id: tests
        run: |
          mkdir coverage
          pytest --cov=pymodaq_utils --ignore-glob='*legacy*' -n 1
          mv .coverage coverage/coverage_${{ matrix.os }}_${{ matrix.python-version }}
      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4.6.2
        with:
          name: coverage-${{ matrix.os }}-${{ matrix.python-version }}
          path: coverage/coverage_${{ matrix.os }}_${{ matrix.python-version }}


     
      - name: Create destination directory
        if: ${{ always() }}
        run: |
          mkdir -p "${{ steps.extract_branch.outputs.branch }}"

      - name: generate badge (success)
        if: ${{ success() }}
        uses: emibcn/badge-action@v2.0.3
        with:
          label: ''
          status: 'passing'
          color: 'green'
          path: '${{ steps.extract_branch.outputs.branch }}/tests_${{runner.os}}_${{matrix.python-version}}.svg'
      - name: generate badge (fail)
        if: ${{ failure() }}
        uses: emibcn/badge-action@v2.0.3
        with:
          label: ''
          status: 'failing'
          color: 'red'
          path: '${{ steps.extract_branch.outputs.branch }}/tests_${{runner.os}}_${{matrix.python-version}}.svg'


      - name: Upload badge artifact
        if: ${{ always() }}
        uses: actions/upload-artifact@v4.6.2
        with:
          name:  tests_${{runner.os}}_${{matrix.python-version}}
          path: '${{ steps.extract_branch.outputs.branch }}/tests_${{runner.os}}_${{matrix.python-version}}.svg'
          if-no-files-found: error 
    
    outputs:
      branch: ${{ steps.extract_branch.outputs.branch }}
     
  badge-update:
    if: github.repository_owner == 'PyMoDAQ'
    runs-on: ubuntu-latest
    needs: tests # Ensure this job runs after all matrix jobs complete
    steps:
       # switch to badges branches to commit
      - uses: actions/checkout@v4.2.2
        with:
          ref: badges
     
      - name: Download badges
        uses: actions/download-artifact@v4.3.0

      - name: Reorganize badges
        run: |
          rm -rf coverage* || true
          rm -rf $(git ls-files ${{ needs.tests.outputs.branch }}/*) || true
          git rm $(git ls-files ${{ needs.tests.outputs.branch }}/*) || true

          mkdir -p '${{ needs.tests.outputs.branch }}'
          mv tests_*/*.svg '${{ needs.tests.outputs.branch }}'
      - name: Commit badges
        continue-on-error: true
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add ${{ needs.tests.outputs.branch }}
          git commit  --allow-empty -m "Add/Update badge"

      - name: Push badges
        uses: ad-m/github-push-action@v0.8.0
        if: ${{ success() }}
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: badges
  coverage-update:
    runs-on: ubuntu-latest
    needs: tests # Ensure this job runs after all matrix jobs complete

    steps:
      - name: Checkout the repo
        uses: actions/checkout@v4.2.2

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4.3.0
        with:
          path: ./coverage-reports

      - name: Reorganize reports
        run: |
          cd coverage-reports
          rm -rf tests_*
          for folder in *; do
            mv "${folder}"/* .;
          done;
          rmdir --ignore-fail-on-non-empty * || true
          cd ..
      # We only combine linux reports otherwise the tool complains about windows directories ...
      - name: Combine coverage reports
        run: |
          python -m pip install coverage
          coverage combine ./coverage-reports/coverage_*
          coverage xml -i

      - name: Upload combined coverage report to Codecov
        uses: codecov/codecov-action@v5.4.3
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: coverage.xml
</file>

<file path=".github/workflows/updater.yml">
name: GitHub Actions Version Updater

# Controls when the action will run.
on:
  schedule:
    # Automatically run at 00:00 on day-of-month 5.
    - cron:  '0 0 5 * *'

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4.2.2
        with:
          # [Required] Access token with `workflow` scope.
          token: ${{ secrets.WORKFLOW_SECRET }}

      - name: Run GitHub Actions Version Updater
        uses: saadmk11/github-actions-version-updater@v0.8.1
        with:
          # [Required] Access token with `workflow` scope.
          token: ${{ secrets.WORKFLOW_SECRET }}
</file>

<file path="src/pymodaq_utils/resources/config_template.toml">
#this is the configuration file of PyMoDAQ
[style]
darkstyle = true
syntax_highlighting = 'github-dark'
language = "English"
country = "UnitedStates"

[qtbackend]
backends = [ "pyqt5", "pyqt6", "pyside2", "pyside6",]
backend = "pyqt6"


[data_saving]
    [data_saving.h5file]
    save_path = "C:\\Data"  #base path where data are automatically saved
    compression_level = 5  # for hdf5 files between 0(min) and 9 (max)

    [data_saving.hsds] #hsds connection option (https://www.hdfgroup.org/solutions/highly-scalable-data-service-hsds/)
    #to save data in pymodaq using hpyd backend towards distant server or cloud (mimicking hdf5 files)
    root_url = "http://hsds.sebastienweber.fr"
    username = "pymodaq_user"
    pwd = "pymodaq"

    [data_saving.data_type]
    dynamic = 'float64' # choose from below. This will force the datatype to be saved to
    dynamics =  ['uint8', 'int8', 'uint16', 'int16', 'uint32', 'int32', 'uint64', 'int64', 'float64']


[general]
debug_level = "INFO" #either "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"
debug_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
check_version = false  # automatically check version at startup (or not if False)
message_status_persistence = 1000  # ms

hdf5_backend = 'tables'  # could be among ['tables', 'h5py', 'h5pyd'], mostly tested with tables

[user]
name = "User name"  # default name used as author in the hdf5 saving files


[plotting]
backend = 'matplotlib'  # either 'matplotlib' or 'qt' or any other custom backend
plot_colors = [[255, 255, 255], [255, 0, 0], [0, 255, 0], [0, 0, 255], [14, 207, 189], [207, 14, 166], [207, 204, 14]]

[network]
    [network.logging]
        [network.logging.user]
        username = "pymodaq_user"
        pwd = "pymodaq"

        [network.logging.sql] #location of the postgresql database server and options where the DAQ_Logger will log data
        ip = "10.47.3.22"
        port = 5432

    [network.tcp-server]
    ip = "10.47.0.39"
    port = 6341

    [network.leco-server]
    run_coordinator_at_startup = false
    host = "localhost"
    port = 12300  # pyleco default Coordinator port

[backup]
keep_backup = true
folder = "environments"
limit = 25
</file>

<file path="src/pymodaq_utils/resources/hatch_build_plugins.py">
logger = set_logger(get_module_name(__file__))
⋮----
def update_metadata_from_toml(metadata: dict, here: Path) -> None
⋮----
src_file = here.joinpath('pyproject.toml')
src_dict = toml.load(src_file)
⋮----
PLUGIN_NAME = metadata['name']
SHORT_PLUGIN_NAME = metadata['name'].split('pymodaq_plugins_')[1]
⋮----
entrypoints = {}
⋮----
# generic plugin, usefull for the plugin manager
</file>

<file path="src/pymodaq_utils/serialize/factory.py">
class SerializableBase(metaclass=ABCMeta)
⋮----
"""Base class for a Serializer. """
⋮----
@classmethod
    def name(cls)
⋮----
"""str: the object class name"""
⋮----
@classmethod
    def type(cls)
⋮----
"""object: the type of the object"""
⋮----
@staticmethod
@abstractmethod
    def serialize(obj: "SerializableBase") -> bytes
⋮----
"""  Implements self serialization into bytes

        Parameters
        ----------
        obj: SerializableBase

        Returns
        -------
        bytes

        Notes
        -----
        The actual serialization should be done using the SerializableFactory and its method
        :meth:SerializableFactory.get_apply_serializer
        """
⋮----
@staticmethod
@abstractmethod
    def deserialize(bytes_str: bytes) -> Tuple["SerializableBase", bytes]
⋮----
""" Implements deserialization into self type from bytes

        Parameters
        ----------
        bytes_str: bytes

        Returns
        -------
        SerializableBase: object to reconstruct
        bytes: leftover bytes to deserialize

        Notes
        -----
        The actual deserialization should be done using the SerializableFactory and its method
        :meth:SerializableFactory.get_apply_deserializer
        """
⋮----
# List of all objects serializable via the serializer
SERIALIZABLE = Union[None, bytes, str, int, float, complex, list, NDArray, SerializableBase]
⋮----
Serializable = TypeVar("Serializable", bound=SERIALIZABLE)
_SerializableClass = TypeVar("_SerializableClass", bound=SerializableBase)
⋮----
Serializer = Callable[[Serializable], bytes]
Deserializer = Callable[[bytes], Tuple[Serializable, bytes]]
⋮----
class SerializableFactory
⋮----
"""The factory class for creating executors"""
⋮----
serializable_registry: dict[type[SERIALIZABLE], dict[str, Union[Serializer, Deserializer]]] = {}
⋮----
def wrap(obj: Serializable) -> bytes
⋮----
bytes_str = b''
⋮----
"""Method to register a serializable object class to the internal registry.

        """
obj_type = obj.__class__
⋮----
@classmethod
    def register_decorator(cls) -> Callable[[type[_SerializableClass]], type[_SerializableClass]]
⋮----
"""Class decorator method to register exporter class to the internal registry. Must be used as
        decorator above the definition of a SerializableBase inherited class.

        This class must implement specific class methods in particular: serialize and deserialize
        """
⋮----
# Return wrapped_class
⋮----
def get_type_from_str(self, obj_type_str: str) -> type
⋮----
def get_serializables(self) -> List[type]
⋮----
def get_serializer(self, obj_type: type) -> Serializer
⋮----
entry_dict = self.serializable_registry.get(obj_type, None)
⋮----
return entry_dict['serializer']  # type: ignore
⋮----
def get_apply_serializer(self, obj: SERIALIZABLE, append_length=False) -> bytes
⋮----
"""

        Parameters
        ----------
        obj: object
            should be a serializable object (see get_serializables)
        append_length: bool
            if True will append the length of the bytes string in the beginning of the returned
            bytes

        Returns
        -------
        bytes: the encoded object

        Notes
        -----
        Symmetric method of :meth:SerializableFactory.get_apply_deserializer

        Examples
        --------
        >>> ser_factory = SerializableFactory()
        >>> s = [23, 'a']
        >>>> ser_factory.get_apply_deserializer(ser_factory.get_apply_serializer(s) == s
        """
serializer = self.get_serializer(obj.__class__)
bytes_str = serializer(obj)
⋮----
bytes_str = utils.int_to_bytes(len(bytes_str)) + bytes_str
⋮----
def get_deserializer(self, obj_type: type[Serializable]) -> Deserializer[Serializable]
⋮----
return entry_dict['deserializer']  # type: ignore
⋮----
""" Infer which object is to be deserialized from the first bytes

        The type has been encoded by the get_apply_serializer method

        Parameters
        ----------
        bytes_str: bytes
            The bytes to convert back to an object
        only_object: bool (default False)
            if False, return the object and the remaining bytes if any
            if True return only the object

        Returns
        -------
        object: the reconstructed object
        optional bytes: only if only_object parameter is False, will be the leftover bytes

        Notes
        -----
        Symmetric method of :meth:SerializableFactory.get_apply_serializer

        Examples
        --------
        >>> ser_factory = SerializableFactory()
        >>> s = [23, 'a']
        >>>> ser_factory.get_apply_deserializer(ser_factory.get_apply_serializer(s) == s
        """
⋮----
obj_type = self.get_type_from_str(obj_type_str)
⋮----
result = self.get_deserializer(obj_type)(remaining_bytes)
</file>

<file path="src/pymodaq_utils/serialize/mysocket.py">
ser_factory = SerializableFactory()
⋮----
class SocketString
⋮----
"""Mimic the Socket object but actually using a bytes string not a socket connection

    Implements a minimal interface of two methods

    Parameters
    ----------
    bytes_string: bytes

    See Also
    --------
    :class:`~pymodaq.utils.tcp_ip.mysocket.Socket`
    """
def __init__(self, bytes_string: bytes)
⋮----
def to_bytes(self)
⋮----
def check_received_length(self, length: int) -> bytes
⋮----
"""
        Make sure all bytes (length) that should be received are received through the socket.

        Here just read the content of the underlying bytes string

        Parameters
        ----------
        length: int
            The number of bytes to be read from the socket

        Returns
        -------
        bytes
        """
data = self._bytes_string[0:length]
⋮----
def get_first_nbytes(self, length: int) -> bytes
⋮----
""" Read the first N bytes from the socket

        Parameters
        ----------
        length: int
            The number of bytes to be read from the socket

        Returns
        -------
        bytes
            the read bytes string
        """
⋮----
class Socket(Socket)
⋮----
"""Custom Socket wrapping the built-in one and added functionalities to
    make sure message have been sent and received entirely"""
⋮----
def check_sended(self, data_bytes: bytes)
⋮----
"""
        Make sure all bytes are sent through the socket
        Parameters
        ----------
        data_bytes: bytes
        """
⋮----
sended = 0
⋮----
def check_sended_with_serializer(self, obj: SERIALIZABLE)
⋮----
""" Convenience function to convert permitted objects to bytes and then use
        the check_sended method

        Appends to bytes the length of the message to make sure the reception knows how much bytes
        to expect

        For a list of allowed objects, see :meth:`Serializer.to_bytes`
        """
# do not use Serializer anymore but mimic its behavior
⋮----
def check_receiving(self, bytes_str: bytes)
⋮----
""" First read the 4th first bytes to get the total message length
        Make sure to read that much bytes before processing the message

        See check_sended and check_sended_with_serializer for a symmetric action
        """
⋮----
bytes_len = utils.bytes_to_int(bytes_len_bytes)
</file>

<file path="src/pymodaq_utils/serialize/serializer_legacy.py">
ser_factory = SerializableFactory()
⋮----
class Serializer
⋮----
"""Used to Serialize to bytes python objects, numpy arrays and PyMoDAQ DataWithAxes and
    DataToExport objects

    Deprecated in PyMoDAQ >= 5 use the SerializerFactory object
    """
⋮----
def __init__(self, obj: Optional[SERIALIZABLE] = None) -> None
⋮----
def to_bytes(self)
⋮----
""" Generic method to obtain the bytes string from various objects

        Compatible objects are:

        * :class:`bytes`
        * :class:`numbers.Number`
        * :class:`str`
        * :class:`numpy.ndarray`
        * :class:`~pymodaq.utils.data.Axis`
        * :class:`~pymodaq.utils.data.DataWithAxes` and sub-flavours
        * :class:`~pymodaq.utils.data.DataToExport`
        * :class:`list` of any objects above

        """
⋮----
def to_b64_string(self) -> str
⋮----
b = self.to_bytes()
⋮----
def bytes_serialization(self, bytes_string_in: bytes) -> bytes
⋮----
""" Convert a bytes string into a bytes message together with the info to convert it back"""
⋮----
def string_serialization(self, string: str) -> bytes
⋮----
""" Convert a string into a bytes message together with the info to convert it back

        Parameters
        ----------
        string: str

        Returns
        -------
        bytes: the total bytes message to serialize the string
        """
⋮----
def scalar_serialization(self, scalar: complex) -> bytes
⋮----
""" Convert a scalar into a bytes message together with the info to convert it back

        Parameters
        ----------
        scalar: A python number (complex or subtypes like float and int)

        Returns
        -------
        bytes: the total bytes message to serialize the scalar
        """
⋮----
def ndarray_serialization(self, array: np.ndarray) -> bytes
⋮----
""" Convert a ndarray into a bytes message together with the info to convert it back

        Parameters
        ----------
        array: np.ndarray

        Returns
        -------
        bytes: the total bytes message to serialize the scalar

        Notes
        -----

        The bytes sequence is constructed as:

        * get data type as a string
        * reshape array as 1D array and get the array dimensionality (len of array's shape)
        * convert Data array as bytes
        * serialize data type
        * serialize data length
        * serialize data shape length
        * serialize all values of the shape as integers converted to bytes
        * serialize array as bytes
        """
⋮----
def object_type_serialization(self, obj: Any) -> bytes
⋮----
""" Convert an object type into a bytes message as a string together with the info to
        convert it back

        """
⋮----
def axis_serialization(self, axis: 'Axis') -> bytes
⋮----
""" Convert an Axis object into a bytes message together with the info to convert it back

        Parameters
        ----------
        axis: Axis

        Returns
        -------
        bytes: the total bytes message to serialize the Axis

        Notes
        -----

        The bytes sequence is constructed as:

        * serialize the type: 'Axis'
        * serialize the axis label
        * serialize the axis units
        * serialize the axis array
        * serialize the axis
        * serialize the axis spread_order
        """
⋮----
def list_serialization(self, list_object: List) -> bytes
⋮----
""" Convert a list of objects into a bytes message together with the info to convert it back

        Parameters
        ----------
        list_object: list
            the list could contains either scalars, strings or ndarrays or Axis objects or DataWithAxis objects
            module

        Returns
        -------
        bytes: the total bytes message to serialize the list of objects

        Notes
        -----

        The bytes sequence is constructed as:
        * the length of the list

        Then for each object:

        * get data type as a string
        * use the serialization method adapted to each object in the list
        """
⋮----
def dwa_serialization(self, dwa: 'DataWithAxes') -> bytes
⋮----
""" Convert a DataWithAxes into a bytes string

        Parameters
        ----------
        dwa: DataWithAxes

        Returns
        -------
        bytes: the total bytes message to serialize the DataWithAxes

        Notes
        -----
        The bytes sequence is constructed as:

        * serialize the string type: 'DataWithAxes'
        * serialize the timestamp: float
        * serialize the name
        * serialize the source enum as a string
        * serialize the dim enum as a string
        * serialize the distribution enum as a string
        * serialize the list of numpy arrays
        * serialize the list of labels
        * serialize the origin
        * serialize the nav_index tuple as a list of int
        * serialize the list of axis
        * serialize the errors attributes (None or list(np.ndarray))
        * serialize the list of names of extra attributes
        * serialize the extra attributes
        """
⋮----
def dte_serialization(self, dte: 'DataToExport') -> bytes
⋮----
""" Convert a DataToExport into a bytes string

        Parameters
        ----------
        dte: DataToExport

        Returns
        -------
        bytes: the total bytes message to serialize the DataToExport

        Notes
        -----
        The bytes sequence is constructed as:

        * serialize the string type: 'DataToExport'
        * serialize the timestamp: float
        * serialize the name
        * serialize the list of DataWithAxes
        """
⋮----
"""Serialize an object with its type, such that it can be retrieved by
        `DeSerializer.type_and_object_deserialization`.
        """
⋮----
obj = self._obj
⋮----
class DeSerializer
⋮----
"""Used to DeSerialize bytes to python objects, numpy arrays and PyMoDAQ Axis,
     DataWithAxes and DataToExport
    objects

    Parameters
    ----------
    bytes_string: bytes or Socket
        the bytes string to deserialize into an object: int, float, string, arrays, list, Axis, DataWithAxes...
        Could also be a Socket object reading bytes from the network having a `get_first_nbytes` method

    See Also
    --------
    :py:class:`~pymodaq_data.serialize.mysocket.SocketString`
    :py:class:`~pymodaq_data.serialize.mysocket.Socket`
    """
⋮----
def __init__(self, bytes_string:  Union[bytes, Socket,] = None) -> None
⋮----
bytes_string = SocketString(bytes_string)
⋮----
def get_message_length(self) -> int
⋮----
@classmethod
    def from_b64_string(cls, b64_string: Union[bytes, str]) -> "DeSerializer"
⋮----
def bytes_deserialization(self) -> bytes
⋮----
bstring_len = self.get_message_length()
bytes_str = self._bytes_string.check_received_length(bstring_len)
⋮----
def string_deserialization(self) -> str
⋮----
"""Convert bytes into a str object

        Convert first the fourth first bytes into an int encoding the length of the string to decode

        Returns
        -------
        str: the decoded string
        """
⋮----
str_obj = ser_factory.get_apply_deserializer(bytes_str)
⋮----
def scalar_deserialization(self) -> complex
⋮----
"""Convert bytes into a python number object

        Get first the data type from a string deserialization, then the data length and finally convert this
        length of bytes into a number (float, int)

        Returns
        -------
        numbers.Number: the decoded number
        """
⋮----
scalar = ser_factory.get_apply_deserializer(bytes_str)
⋮----
def boolean_deserialization(self) -> bool
⋮----
"""Convert bytes into a boolean object

        Get first the data type from a string deserialization, then the data length and finally
        convert this length of bytes into a number (float, int) and cast it to a bool

        Returns
        -------
        bool: the decoded boolean
        """
⋮----
def ndarray_deserialization(self) -> np.ndarray
⋮----
"""Convert bytes into a numpy ndarray object

        Convert the first bytes into a ndarray reading first information about the array's data

        Returns
        -------
        ndarray: the decoded numpy array
        """
⋮----
array = ser_factory.get_apply_deserializer(bytes_str)
⋮----
def type_and_object_deserialization(self) -> SERIALIZABLE
⋮----
""" Deserialize specific objects from their binary representation (inverse of `Serializer.type_and_object_serialization`).

        See Also
        --------
        Serializer.dwa_serialization, Serializer.dte_serialization

        """
⋮----
obj = ser_factory.get_apply_deserializer(bytes_str)
⋮----
def list_deserialization(self) -> list
⋮----
"""Convert bytes into a list of homogeneous objects

        Convert the first bytes into a list reading first information about the list elt types, length ...

        Returns
        -------
        list: the decoded list
        """
⋮----
def parameter_deserialization(self)
⋮----
def axis_deserialization(self) -> 'Axis'
⋮----
"""Convert bytes into an Axis object

        Convert the first bytes into an Axis reading first information about the Axis

        Returns
        -------
        Axis: the decoded Axis
        """
⋮----
def dwa_deserialization(self) -> 'DataWithAxes'
⋮----
"""Convert bytes into a DataWithAxes object

        Convert the first bytes into a DataWithAxes reading first information about the underlying data

        Returns
        -------
        DataWithAxes: the decoded DataWithAxes
        """
⋮----
def dte_deserialization(self) -> 'DataToExport'
⋮----
"""Convert bytes into a DataToExport object

        Convert the first bytes into a DataToExport reading first information about the underlying data

        Returns
        -------
        DataToExport: the decoded DataToExport
        """
</file>

<file path="src/pymodaq_utils/serialize/serializer.py">
# -*- coding: utf-8 -*-
"""
Created the 20/10/2023

@author: Sebastien Weber
"""
⋮----
ser_factory = SerializableFactory()
⋮----
class NoneSerializeDesieralize(SerializableBase)
⋮----
@staticmethod
    def serialize(obj: None) -> bytes:  # type: ignore[override]
⋮----
@staticmethod
    def deserialize(bytes_str: bytes) -> Tuple[None, bytes]:  # type: ignore[override]
⋮----
class StringSerializeDeserialize(SerializableBase)
⋮----
@staticmethod
    def serialize(string: str) -> bytes
⋮----
""" Convert a string into a bytes message together with the info to convert it back

        Parameters
        ----------
        string: str

        Returns
        -------
        bytes: the total bytes message to serialize the string
        """
bytes_string = b''
⋮----
@staticmethod
    def deserialize(bytes_str) -> Tuple[str, bytes]
⋮----
"""Convert bytes into a str object

        Convert first the fourth first bytes into an int encoding the length of the string to decode

        Returns
        -------
        str: the decoded string
        bytes: the remaining bytes string if any
        """
⋮----
str_obj = utils.bytes_to_string(str_bytes)
⋮----
class BytesSerializeDeserialize(SerializableBase)
⋮----
@staticmethod
    def serialize(some_bytes: bytes) -> bytes
⋮----
@staticmethod
    def deserialize(bytes_str: bytes) -> Tuple[bytes, bytes]
⋮----
class ScalarSerializeDeserialize(SerializableBase)
⋮----
@staticmethod
    def serialize(scalar: complex) -> bytes
⋮----
""" Convert a scalar into a bytes message together with the info to convert it back

        Parameters
        ----------
        scalar: A python number (complex or subtypes like float and int)

        Returns
        -------
        bytes: the total bytes message to serialize the scalar
        """
⋮----
# type hint is complex, instance comparison Number
⋮----
scalar_array = np.array([scalar])
data_type = scalar_array.dtype.descr[0][1]
data_bytes = scalar_array.tobytes()
⋮----
@staticmethod
    def deserialize(bytes_str: bytes) -> Tuple[complex, bytes]
⋮----
"""Convert bytes into a python object of type (float, int, complex or boolean)

        Get first the data type from a string deserialization, then the data length and finally convert this
        length of bytes into an object of type (float, int, complex or boolean)

        Returns
        -------
        numbers.Number: the decoded number
        bytes: the remaining bytes string if any
        """
⋮----
number = np.frombuffer(number_bytes, dtype=data_type)[0]
⋮----
number = float(number)  # because one get numpy float type
⋮----
number = int(number)  # because one get numpy int type
⋮----
number = complex(number)  # because one get numpy complex type
⋮----
number = bool(number)  # because one get numpy complex type
⋮----
class NdArraySerializeDeserialize(SerializableBase)
⋮----
@staticmethod
    def serialize(array: np.ndarray) -> bytes
⋮----
""" Convert a ndarray into a bytes message together with the info to convert it back

        Parameters
        ----------
        array: np.ndarray

        Returns
        -------
        bytes: the total bytes message to serialize the scalar

        Notes
        -----

        The bytes sequence is constructed as:

        * get data type as a string
        * reshape array as 1D array and get the array dimensionality (len of array's shape)
        * convert Data array as bytes
        * serialize data type
        * serialize data length
        * serialize data shape length
        * serialize all values of the shape as integers converted to bytes
        * serialize array as bytes
        """
⋮----
array_type = array.dtype.descr[0][1]
array_shape = array.shape
⋮----
array = array.reshape(array.size)
array_bytes = array.tobytes()
⋮----
@staticmethod
    def deserialize(bytes_str: bytes) -> Tuple[np.ndarray, bytes]
⋮----
"""Convert bytes into a numpy ndarray object

        Convert the first bytes into a ndarray reading first information about the array's data

        Returns
        -------
        ndarray: the decoded numpy array
        bytes: the remaining bytes string if any
        """
⋮----
shape = []
⋮----
ndarray = np.frombuffer(ndarray_bytes, dtype=ndarray_type)
ndarray = ndarray.reshape(tuple(shape))
ndarray = np.atleast_1d(ndarray)  # remove singleton dimensions
⋮----
class ListSerializeDeserialize(SerializableBase)
⋮----
@staticmethod
    def serialize(list_object: List) -> bytes
⋮----
""" Convert a list of objects into a bytes message together with the info to convert it back

        Parameters
        ----------
        list_object: list
            the list could contain whatever objects are registered in the SerializableFactory

        Returns
        -------
        bytes: the total bytes message to serialize the list of objects

        Notes
        -----

        The bytes sequence is constructed as:
        * the length of the list

        Then for each object:
        * use the serialization method adapted to each object in the list
        """
⋮----
@staticmethod
    def deserialize(bytes_str: bytes) -> Tuple[List[SERIALIZABLE], bytes]
⋮----
"""Convert bytes into a list of objects

        Convert the first bytes into a list reading first information about the list elt types, length ...

        Returns
        -------
        list: the decoded list
        bytes: the remaining bytes string if any
        """
list_obj = []
⋮----
class SerializableTypes(Enum)
⋮----
"""Type names of serializable types"""
NONE = "NoneType"  # just in case it is needed
BOOL = "bool"
BYTES = "bytes"
STRING = "string"
SCALAR = "scalar"
LIST = "list"
ARRAY = "array"
AXIS = "axis"
DATA_WITH_AXES = "dwa"
DATA_TO_EXPORT = "dte"
PARAMETER = "parameter"
</file>

<file path="src/pymodaq_utils/serialize/utils.py">
def split_nbytes(bytes_str: bytes, bytes_len: int) -> Tuple[bytes, bytes]
⋮----
def get_int_from_bytes(bytes_str: bytes) -> Tuple[int, bytes]
⋮----
""" Convert the 4 first bytes into an integer
    Returns
    -------
    int: the decoded integer
    bytes: the remaining bytes string if any
    """
⋮----
int_obj = bytes_to_int(int_bytes)
⋮----
def bytes_to_string(message: bytes) -> str
⋮----
def bytes_to_int(bytes_string: bytes) -> int
⋮----
"""Convert a bytes of length 4 into an integer"""
⋮----
def bytes_to_scalar(data: bytes, dtype: np.dtype) -> complex
⋮----
"""Convert bytes to a scalar given a certain numpy dtype

    Parameters
    ----------
    data: bytes
    dtype:np.dtype

    Returns
    -------
    numbers.Number
    """
⋮----
def bytes_to_nd_array(data: bytes, dtype: np.dtype, shape: Tuple[int]) -> np.ndarray
⋮----
"""Convert bytes to a ndarray given a certain numpy dtype and shape

    Parameters
    ----------
    data: bytes
    dtype: np.dtype
    shape: tuple of int

    Returns
    -------
    np.ndarray
    """
array = np.frombuffer(data, dtype=dtype)
array = array.reshape(tuple(shape))
array = np.atleast_1d(array)  # remove singleton dimensions but keeping ndarrays
⋮----
def int_to_bytes(an_integer: int) -> bytes
⋮----
"""Convert an unsigned integer into a byte array of length 4 in big endian

    Parameters
    ----------
    an_integer: int

    Returns
    -------
    bytearray
    """
⋮----
def str_to_bytes(message: str) -> bytes
⋮----
def str_len_to_bytes( message: Union[str, bytes]) -> Tuple[bytes, bytes]
⋮----
""" Convert a string and its length to two bytes
    Parameters
    ----------
    message: str
        the message to convert

    Returns
    -------
    bytes: message converted as a byte array
    bytes: length of the message byte array, itself as a byte array of length 4
    """
⋮----
message = str(message)
⋮----
message = str_to_bytes(message)
</file>

<file path="src/pymodaq_utils/__init__.py">
__version__ = get_version('pymodaq_utils')
⋮----
__version__ = '0.0.0dev'
⋮----
logger_var = set_logger('pymodaq', add_handler=True, base_logger=True)
⋮----
CONFIG = Config()  # to ckeck for config file existence, otherwise create one
</file>

<file path="src/pymodaq_utils/abstract.py">
# -*- coding: utf-8 -*-
"""
Created the 21/11/2022

@author: Sebastien Weber

Introduce some nice ABCMeta class allowing that a particular attribute has been declared when instantiating
See https://stackoverflow.com/a/50381071/8090831
"""
⋮----
R = TypeVar('R')
⋮----
class DummyAttribute
⋮----
def abstract_attribute(obj: Callable[[Any], R] = None) -> R
⋮----
_obj = cast(Any, obj)
⋮----
_obj = DummyAttribute()
⋮----
class ABCMeta(NativeABCMeta)
⋮----
def __call__(cls, *args, **kwargs)
⋮----
instance = NativeABCMeta.__call__(cls, *args, **kwargs)
abstract_attributes = {
</file>

<file path="src/pymodaq_utils/array_manipulation.py">
# -*- coding: utf-8 -*-
"""
Created on Mon March 03 2021
author: Sebastien Weber
"""
⋮----
def random_step(start, stop, step)
⋮----
tmp = start
out = np.array([tmp])
sign = stop - start
⋮----
tmp = tmp + (np.random.random() + 0.5) * step
out = np.append(out, tmp)
⋮----
def linspace_this_vect(x, y=None, Npts=None)
⋮----
"""
        Given a vector x, it returns a vector xlin where xlin is a
        linearised version of x on the same interval and with the same size.
        if args is provided it is a y vector and the function returns both xlin
        and ylin where ylin is a linear interpolation of y on this new xlin axis
    
        Parameters
        ----------
        x : (ndarray)
        y : (ndarray) optional
        Npts: (int) size of the linear vector (optional)

        Returns
        -------
        xlin : vector
        (ylin : vector) optional if args is provided

    """
⋮----
Npts = np.size(x)
xlin = np.linspace(np.min(x), np.max(x), Npts)
⋮----
ylin = np.interp(xlin, x, y)
⋮----
def find_index(x, threshold)
⋮----
"""
    find_index finds the index ix such that x(ix) is the closest from threshold
    
    Parameters
    ----------
    x : vector
    threshold : list of scalar

    Returns
    -------
    out : list of 2-tuple containing ix,x[ix]
            out=[(ix0,xval0),(ix1,xval1),...]
    """
⋮----
threshold = [threshold]
out = []
⋮----
ix = int(np.argmin(np.abs(x - value)))
⋮----
def find_rising_edges(x, threshold)
⋮----
"""find_rising_edges finds the index ix such that x(ix) is the closest from threshold and values are increasing
    
    Parameters
    ----------
    x : vector
    threshold : list of scalar

    Returns
    -------
    out : list of 2-tuple containing ix,x[ix]
            out=[(ix0,xval0),(ix1,xval1),...]
    
    """
x_shifted = np.concatenate((x[1:], np.array((np.nan,))))
⋮----
dat = np.bitwise_and(x < value, x_shifted > value)
ix = [ind for ind, flag in enumerate(dat) if flag]
⋮----
def crop_vector_to_axis(x, V, xlim)
⋮----
"""crops a vector V with given x axis vector to a given xlim tuple
    
    Parameters
    ----------
    x : vector
    V : vector
    xlim: tuple containing (xmin,xmax)
    
    Returns
    -------
    x_c : vector
    V_c : vector
    """
x1 = find_index(x, xlim[0])[0][0]
x2 = find_index(x, xlim[1])[0][0]
⋮----
ixx = np.linspace(x1, x2, x2 - x1 + 1, dtype=int);
⋮----
ixx = np.linspace(x2, x1, x1 - x2 + 1, dtype=int);
⋮----
x_c = x[ixx]
V_c = V[ixx]
⋮----
def rescale(x, window=[0.0, 1.0])
⋮----
""" Rescales a numpy array to the range specified by ``window``.

    Default is [0, 1].
    """
maxx = np.max(x)
minx = np.min(x)
⋮----
def marginals(data, normalize=False, axes=None)
⋮----
""" Calculates the marginals of the data array.

    axes specifies the axes of the marginals, e.g., the axes on which the
    sum is projected.

    If axis is None a list of all marginals is returned.
    """
⋮----
axes = range(data.ndim)
axes = list(axes)
full_axes = list(range(data.ndim))
m = []
⋮----
# for the marginal sum over all axes except the specified one
margin_axes = tuple(j for j in full_axes if j != i)
⋮----
m = [rescale(mx) for mx in m]
⋮----
def find(x, condition, n=1)
⋮----
""" Return the index of the nth element that fulfills the condition.
    """
search_n = 1
⋮----
def arglimit(y, threshold=1e-3, padding=0.0, normalize=True)
⋮----
""" Returns the first and last index where `y >= threshold * max(abs(y))`.
    """
t = np.abs(y)
⋮----
t = t / np.max(t)
⋮----
idx1 = find(t, lambda x: x >= threshold)
⋮----
idx1 = 0
idx2 = find(t[::-1], lambda x: x >= threshold)
⋮----
idx2 = t.shape[0] - 1
⋮----
idx2 = t.shape[0] - 1 - idx2
⋮----
def limit(x, y=None, threshold=1e-3, padding=0.25, extend=True)
⋮----
""" Returns the maximum x-range where the y-values are sufficiently large.

    Parameters
    ----------
    x : array_like
        The x values of the graph.
    y : array_like, optional
        The y values of the graph. If `None` the maximum range of `x` is
        used. That is only useful if `padding > 0`.
    threshold : float
        The threshold relative to the maximum of `y` of values that should be
        included in the bracket.
    padding : float
        The relative padding on each side in fractions of the bracket size.
    extend : bool, optional
        Signals if the returned range can be larger than the values in ``x``.
        Default is `True`.

    Returns
    -------
    xl, xr : float
        Lowest and biggest value of the range.

    """
⋮----
# calculate the padding
⋮----
pad = (x2 - x1) * padding
⋮----
x1 = max(x1, np.min(x))
x2 = min(x2, np.max(x))
⋮----
def crop_array_to_axis(x, y, M, cropbox)
⋮----
"""crops an array M with given cropbox as a tuple (xmin,xmax,ymin,ymax).
    
    Parameters
    ----------
    x : vector
    y : vector
    M : 2D array
    cropbox: 4 elements tuple containing (xmin,xmax,ymin,ymax)
    
    Returns
    -------
    x_c : croped x vector
    y_c : croped y  vector
    M_c : croped 2D M array

    """
x1 = find_index(x, cropbox[0])[0][0]
x2 = find_index(x, cropbox[1])[0][0]
⋮----
ixx = np.linspace(x1, x2, x2 - x1 + 1, dtype=int)
⋮----
ixx = np.linspace(x2, x1, x1 - x2 + 1, dtype=int)
⋮----
y1 = find_index(y, cropbox[2])[0][0]
y2 = find_index(y, cropbox[3])[0][0]
⋮----
iyy = np.linspace(y1, y2, y2 - y1 + 1, dtype=int)
⋮----
iyy = np.linspace(y2, y1, y1 - y2 + 1, dtype=int)
⋮----
y_c = y[iyy]
⋮----
M_c = M[iyy[0]:iyy[-1] + 1, ixx[0]:ixx[-1] + 1]
⋮----
def interp1D(x, M, xlin, axis=1)
⋮----
"""
    same as numpy interp function but works on 2D array
    you have to specify the axis over which to do the interpolation
    kwargs refers to the numpy interp kwargs
    returns both xlin and the new 2D array Minterp
    """
⋮----
Minterp = np.zeros((np.size(xlin), np.size(M, axis=1)))
indexes = np.arange(0, np.size(M, axis=1))
⋮----
#             print(ind)
⋮----
Minterp = np.zeros((np.size(M, axis=0), np.size(xlin)))
indexes = np.arange(0, np.size(M, axis=0))
⋮----
def linspace_this_image(x, M, axis=1, Npts=None)
⋮----
"""
    Given a vector x and a 2D array M, it returns an array vector xlin where xlin is a
    linearised version of x on the same interval and with the same size. it returns as well
    a 2D array Minterp interpolated on the new xlin vector along the specified axis.

    Parameters
    ----------
    x : (vector)
    M : (2D array)
    axis : (int)
    Npts: (int) size of the linear vector (optional)

    Returns
    -------
    xlin : vector
    Minterp : 2D array
    """
xlin = linspace_this_vect(x, Npts=Npts)
Minterp = interp1D(x, M, xlin, axis=axis)
⋮----
def max_ind(x, axis=None)
⋮----
"""returns the max value in a vector or array and its index (in a tuple)

    Parameters
    ----------
    x : vector
    
    axis : optional dimension aginst which to normalise
      
    Returns
    -------
    ind_max : index of the maximum value
    
    max_val : maximum value
    """
ind_max = np.argmax(x, axis=axis)
max_val = np.max(x, axis=axis)
⋮----
def min_ind(x, axis=None)
⋮----
"""returns the min value in a vector or array and its index (in flattened array)

    Parameters
    ----------
    x : vector
    axis : optional dimension to check the function

    Returns
    -------
    ind_min : index of the minimum value
    min_val : minimum value
    """
ind_min = np.argmin(x, axis=axis)
min_val = np.min(x, axis=axis)
⋮----
if __name__ == '__main__':                                          # pragma: no cover
⋮----
x = random_step(00, 100, 5)
y = random_step(00, 100, 5)
g2 = utils.gauss2D(x, 35, 15, y, 55, 20, 1)
</file>

<file path="src/pymodaq_utils/config.py">
USER = environ['USERNAME'] if sys.platform == 'win32' else environ['USER']
⋮----
USER = 'unknown_user'
⋮----
CONFIG_BASE_PATH = Path(environ['PROGRAMDATA']) if sys.platform == 'win32' else \
⋮----
KeyType = TypeVar('KeyType')
⋮----
def deep_update(mapping: Dict[KeyType, Any], *updating_mappings: Dict[KeyType, Any]) -> Dict[KeyType, Any]
⋮----
""" Make sure a dictionary is updated using another dict in any nested level
    Taken from Pydantic v1
    """
updated_mapping = mapping.copy()
⋮----
def replace_file_extension(filename: str, ext: str)
⋮----
"""Replace the extension of a file by the specified one, without the dot"""
file_name = Path(filename).stem  # remove eventual extensions
⋮----
ext = ext[1:]
⋮----
def getitem_recursive(dic, *args, ndepth=0, create_if_missing=False)
⋮----
"""Will scan recursively a dictionary in order to get the item defined by the iterable args

    Parameters
    ----------
    dic: dict
        the dictionary to scan
    args: an iterable of str
        keys of the dict
    ndepth: int
        by default (0) get the last element defined by args. 1 would mean it get the parent dict, 2 the parent of the
        parent...
    create_if_missing: bool
        if the entry is not present, create it assigning the 'none' default value (as a lower case string)
    Returns
    -------
    object or dict
    """
args = list(args)
⋮----
arg = args.pop(0)
dic = dic[arg]
⋮----
dic = 'none'
⋮----
def recursive_iterable_flattening(aniterable: IterableType)
⋮----
flatten_iter = []
⋮----
def get_set_path(a_base_path: Path, dir_name: str) -> Path
⋮----
path_to_get = a_base_path.joinpath(dir_name)
⋮----
path_to_get = Path.home().joinpath(dir_name)
⋮----
def get_set_local_dir(user=False) -> Path
⋮----
"""Defines, creates and returns a local folder where configuration files will be saved

    Depending on the os the configurations files will be stored in CONFIG_BASE_PATH, then
    each user will have another one created that could override the default and system-wide base folder

    Parameters
    ----------
    user: bool
        if False get the system-wide folder, otherwise the user folder

    Returns
    -------
    Path: the local path
    """
⋮----
local_path = get_set_path(Path.home(), '.pymodaq')
⋮----
local_path = get_set_path(CONFIG_BASE_PATH, '.pymodaq')
⋮----
def get_config_file(config_file_name: str, user=False)
⋮----
def get_set_config_dir(config_name='config', user=False)
⋮----
"""Creates a folder in the local config directory to store specific configuration files

    Parameters
    ----------
    config_name: (str) name of the configuration folder
    user: bool
        if False get the system-wide folder, otherwise the user folder

    Returns
    -------
    Path

    See Also
    --------
    get_set_local_dir
    """
⋮----
def get_set_log_path()
⋮----
""" creates and return the config folder path for log files
    """
⋮----
def create_toml_from_dict(mydict: dict, dest_path: Path)
⋮----
"""Create a Toml file at a given path from a dictionnary"""
⋮----
def check_config(config_base: dict, config_local: dict)
⋮----
"""Compare two configuration dictionaries. Adding missing keys

        Parameters
        ----------
        config_base: dict
            The base dictionaries with possible new keys
        config_local: dict
            a dict from a local config file potentially missing keys

        Returns
        -------
        bool: True if keys where missing else False
        """
status = False
⋮----
status = status or check_config(config_base[key], config_local[key])
⋮----
status = True
⋮----
"""Get a toml file path and copy it

    the destination is made of a given folder path (or the system-wide local path by default) and the config_file_name
    appended by the suffix '.toml'

    The source file (or pymodaq config template path by default) is read and dumped in this destination file

    Parameters
    ----------
    config_file_name: str
        the name of the destination config file
    source_path: Path or str
        the path of the toml source to be copied
    dest_path: Path or str
        the destination path of the copied config

    Returns
    -------
    Path: the path of the copied file
    """
⋮----
dest_path = get_set_local_dir()
⋮----
file_name = Path(config_file_name).stem  # remove eventual extensions
⋮----
dest_path_with_filename = dest_path.joinpath(file_name)
⋮----
config_template_dict = {}
⋮----
config_template_dict = toml.load(Path(source_path))
⋮----
def load_system_config_and_update_from_user(config_file_name: str)
⋮----
"""load from a system-wide config file, update it from the user config file

    Parameters
    ----------
    config_file_name: str
        The config file to be loaded
    Returns
    -------
    dict: contains the toml system-wide file update with the user file
    """
config_dict = dict([])
toml_base_path = get_config_file(config_file_name, user=False)
⋮----
config_dict = toml.load(toml_base_path)
toml_user_path = get_config_file(config_file_name, user=True)
⋮----
config_dict = deep_update(config_dict, toml.load(toml_user_path))
⋮----
class ConfigError(Exception)
⋮----
class BaseConfig
⋮----
"""Base class to manage configuration files

    Should be subclassed with proper class attributes for each configuration file you need with pymodaq

    Attributes
    ----------
    config_name: str
        The name with which the configuration will be saved
    config_template_path: Path
        The Path of the template from which the config is constructed

    """
config_template_path: Path = abstractproperty()
config_name: str = abstractproperty()
⋮----
def __init__(self)
⋮----
def __repr__(self)
⋮----
def __call__(self, *args)
⋮----
ret = getitem_recursive(self._config, *args)
⋮----
def __contains__(self, item)
⋮----
def to_dict(self)
⋮----
def __getitem__(self, item)
⋮----
"""for backcompatibility when it was a dictionnary"""
⋮----
# def __setitem__(self, key, value):
#     if isinstance(key, tuple):
#         dic = getitem_recursive(self._config, *key, ndepth=1, create_if_missing=False)
#         dic[key[-1]] = value
#     else:
#         self._config[key] = value
⋮----
def __setitem__(self, key, value)
⋮----
dic = getitem_recursive(self._config, *key, ndepth=1, create_if_missing=True)
if value is None:  # means the setting is a group
value = {}
⋮----
def load_config(self, config_file_name, template_path: Path)
⋮----
"""Load a configuration file from both system-wide and user file

        check also if missing entries in the configuration file compared to the template"""
⋮----
config = toml.load(toml_base_path)
⋮----
config_template = toml.load(template_path)
⋮----
config_template = {}
if check_config(config_template, config):  # check if all fields from template are there
# (could have been  modified by some commits)
⋮----
# create the author from environment variable
config_dict = self.dict_to_add_to_user()
⋮----
config_dict = load_system_config_and_update_from_user(config_file_name)
⋮----
def dict_to_add_to_user(self)
⋮----
"""To subclass"""
⋮----
@property
    def config_path(self)
⋮----
"""Get the user config path"""
⋮----
@property
    def system_config_path(self)
⋮----
"""Get the system_wide config path"""
⋮----
def save(self)
⋮----
"""Save the current Config object into the user toml file"""
⋮----
def get_children(self, *path: IterableType[str])
⋮----
""" Get the list of config entries at a given path within the configulation toml file

        new in 4.3.0
        """
⋮----
class Config(BaseConfig)
⋮----
"""Main class to deal with configuration values for PyMoDAQ"""
config_template_path = Path(__file__).parent.joinpath('resources/config_template.toml')
config_name = 'config_pymodaq_utils'
</file>

<file path="src/pymodaq_utils/enums.py">
from strenum import StrEnum   # noqa  # pylint: disable=unused-import
⋮----
from enum import StrEnum   # noqa  # pylint: disable=unused-import
⋮----
class BaseEnum(Enum)
⋮----
"""Enum to be used within pymodaq with some utility methods"""
⋮----
@classmethod
    def names(cls) -> List[str]
⋮----
"""Returns all the names of the enum"""
⋮----
@classmethod
    def values(cls) -> List[str]
⋮----
@classmethod
    def to_dict(cls)
⋮----
""" Returns the enum in form of a dict with names os keys

        New in 4.0.2
        """
⋮----
@classmethod
    def to_dict_value(cls)
⋮----
""" Returns the enum in form of a dict with values os keys

        New in 4.0.2
        """
⋮----
def __eq__(self, other: Union[str, Enum])
⋮----
"""testing for equality using the enum name"""
⋮----
def enum_checker(enum: BaseEnum, item: Union[BaseEnum, str])
⋮----
"""Check if the item parameter is a valid enum or at least one valid string name of the enum

    If a string, transforms it to a valid enum (case not important)

    Parameters
    ----------
    enum: BaseEnum class or one of its derivated class

    item: str or BaseEnum instance

    Returns
    -------
    BaseEnum class or one of its derivated class
    """
⋮----
item = enum[name]
</file>

<file path="src/pymodaq_utils/environment.py">
logger = set_logger(get_module_name(__file__))
⋮----
config = configmod.Config()
⋮----
def guess_virtual_environment() -> str
⋮----
'''
        Try to guess the current python environment used.

        Returns
        -------
        str: the guessed environment name or the string "unknown"
    '''
def _venv_name_or_path()
⋮----
#Try to guess from system environment
⋮----
value = os.environ.get(var)
⋮----
#if true, probably running in a venv
⋮----
class EnvironmentBackupManager
⋮----
'''
        A class to manage rotating backups of python environments, controlled by entries in 
        [backup] section of the configuration.

    '''
def __init__(self)
⋮----
# Path is: <local_config_path>/<backup_path(default=environments)>/<venv_name>/
⋮----
def _load(self)
⋮----
'''
            Loads and returns all environment backups stored in `self._path` into PythonEnvironment
            objects, then sort them by date.

            Returns
            ----------
            [PythonEnvironment]: 
                A sorted list of PythonEnvironment objects (from oldest to newest)
        '''
environments = []
filenames = list(self._path.glob('*.txt'))
⋮----
def _should_save(self)
⋮----
# current backup should be saved if there's no backup or if it's different from the oldest
⋮----
def _remove_oldest(self)
⋮----
# remove from the list and from disk
env = self._backups.pop(0)
⋮----
def _save_newest(self)
⋮----
# save to disk and the list
⋮----
def save_backup(self)
⋮----
'''
            Save the current environment if there is no backup or if it's different
            from the oldest one.

            Also, remove the oldest one(s) if there's more than the limit defined in configuration.
        '''
⋮----
class PythonEnvironment
⋮----
'''
        A class to represent a python environment and creates/delete backups.

        Preferably, it is instanciated using one the following static method:
         - `from_freeze`: to perform a pip freeze and allowing to save it
         - `from_file`: to read a file and allowing to delete it
    '''
DATE_FORMAT = "%Y%m%d%H%M%S"
⋮----
def __init__(self, filename=None)
⋮----
# set comparison is easy, order does not matter
⋮----
storage_path = get_set_local_dir(user=True) / config['backup']['folder'] / guess_virtual_environment()
⋮----
# Shouldn't be necessary, but ensure it exists
⋮----
def __eq__(self, other)
⋮----
# Two environements are the same if they share the same packages
⋮----
def date(self)
⋮----
'''
            Gets the date at which this environment was created from its filename.
            If not possible it fallbacks to its creation/modification date (depending on the OS)
            If still not possible it fallbacks to now.

            It allows to sort them by date, without having to declare comparison 
            operators that aren't consistant with __eq__.

            Returns
            ----------
            datetime: 
                The date associated with this environment
        '''
⋮----
date_in_filename = self._path.name.split('_')[0]
⋮----
def extend(self, packages)
⋮----
'''
            Add packages to the environment. (This does not install them)

            Parameters
            ----------
            packages: [str]
                an iterable containing the different packages, preferably in a "<name>==<version>" format 
        '''
⋮----
def remove(self)
⋮----
'''
            Remove the backup file associated with this environment, if it exists. 
        '''
⋮----
def save(self)
⋮----
'''
            Save the backup file associated with this environment, if it does not exists. 
        '''
⋮----
header = [f'# executable: {sys.executable}', f'# version: {sys.version}', '']
⋮----
@staticmethod
    def _from_stream(stream, filename=None)
⋮----
env = PythonEnvironment(filename=filename)
⋮----
lines = map(lambda l : l.decode().strip(), s.readlines())
packages = filter(lambda l : l and l != '' and not l.startswith('#'), lines)
⋮----
@staticmethod
    def from_file(filename)
⋮----
'''
            Loads a PythonEnvironment from a text file in a pip recognized format 

            Parameters
            ----------
            filename: str
                A Path to the file to load

            Returns
            -------
            PythonEnvironment: 
                the PythonEnvironment representation of the file 
                represented by `filename`
        '''
⋮----
@staticmethod
    def from_freeze()
⋮----
'''
            Loads a PythonEnvironment by performing a pip freeze 

            Returns
            -------
            PythonEnvironment: 
                the PythonEnvironment representation of all installed
                packages in the current environment
        '''
pip = subprocess.Popen([sys.executable, '-m', 'pip', 'freeze'], stdout=subprocess.PIPE)
</file>

<file path="src/pymodaq_utils/factory.py">
# -*- coding: utf-8 -*-
"""
Created the 04/11/2022

@author: Sebastien Weber
"""
⋮----
logger = set_logger(get_module_name(__file__))
⋮----
class BuilderBase(ABCMeta)
⋮----
"""Abstract class defining an object/service builder with a callable interface accepting some arguments

    See https://realpython.com/factory-method-python/ for some details

    See Also
    --------
    pymodaq.post_treatment.process_1d_to_scalar
    """
⋮----
@abstractmethod
    def __call__(self, *args, **kwargs)
⋮----
class ObjectFactory(metaclass=ABCMeta)
⋮----
"""Generic ObjectFactory with a decorator register to add object builders to the factory with a
    unique key identifier

    See https://realpython.com/factory-method-python/ for some details

    Examples
    --------
    @ObjectFactory.register('custom')
    def my_custom_builder():
        pass

    See Also
    --------
    pymodaq.post_treatment.process_1d_to_scalar.Data1DProcessorFactory
    """
_builders = {}
⋮----
@classmethod
    def register(cls, key: str) -> Callable
⋮----
def inner_wrapper(wrapped_class: Union[BuilderBase, Callable]) -> Callable
⋮----
@property
    def builders(self)
⋮----
def keys_function(self, do_sort=True)
⋮----
@property
    def keys(self)
⋮----
@classmethod
    def create(cls, key, **kwargs)
⋮----
builder = cls._builders[cls.__name__].get(key)
⋮----
@classmethod
    def get_class(cls, key)
</file>

<file path="src/pymodaq_utils/logger.py">
# -*- coding: utf-8 -*-
"""
Created the 27/10/2022

@author: Sebastien Weber
"""
⋮----
config = Config()
⋮----
"""defines a logger of a given name and eventually add an handler to it

    Parameters
    ----------
    logger_name: (str) the name of the logger (usually it is the module name as returned by get_module_name
    add_handler (bool) if True adds a TimedRotatingFileHandler to the logger instance (should be True if logger set from
                main app
    base_logger: (bool) specify if this is the parent logger (usually where one defines the handler)

    Returns
    -------
    logger: (logging.Logger) logger instance
    See Also
    --------
    get_module_name, logging.handlers.TimedRotatingFileHandler
    """
⋮----
logger_name = f'{logger_base_name}.{logger_name}'
⋮----
logger = logging.getLogger(logger_name)
⋮----
log_level = config('general', 'debug_level')
⋮----
log_path = get_set_config_dir('log', user=True)
log_file_path = log_path.joinpath(f'{logger_base_name}.log')
⋮----
handler = TimedRotatingFileHandler(log_file_path, when='midnight')
⋮----
handler = logging.StreamHandler()
⋮----
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
⋮----
# only catch DeprecationWarning in DEBUG level
⋮----
warnings_logger = logging.getLogger("py.warnings")
⋮----
console_handler = logging.StreamHandler()
⋮----
def get_base_logger(logger: logging.Logger) -> logging.Logger
⋮----
logger = logger.parent
⋮----
def get_module_name(module__file__path)
⋮----
"""from the full path of a module extract its name"""
path = Path(module__file__path)
</file>

<file path="src/pymodaq_utils/math_utils.py">
logger = set_logger(get_module_name(__file__))
⋮----
def my_moment(x, y)
⋮----
"""Returns the moments of a distribution y over an axe x

    Parameters
    ----------
    x: list or ndarray
       vector of floats
    y: list or ndarray
       vector of floats corresponding to the x axis

    Returns
    -------
    m: list
       Contains moment of order 0 (mean) and of order 1 (std) of the distribution y
    """
dx = np.mean(np.diff(x))
norm = np.sum(y) * dx
m = [np.sum(x * y) * dx / norm]
⋮----
def normalize(x)
⋮----
x = x - np.min(x)
x = x / np.max(x)
⋮----
def normalize_to(array: np.ndarray, value: numbers.Number)
⋮----
def odd_even(x: Union[int, np.ndarray])
⋮----
"""
    odd_even tells if a number (or an array) is odd (return True) or even (return False)

    Parameters
    ----------
    x: the integer number (or array) to test

    Returns
    -------
    bool : boolean or array of boolean
    """
⋮----
isodd = False
⋮----
isodd = True
⋮----
isodd = x % 2 != 0
⋮----
def greater2n(x)
⋮----
"""
    return the first power of 2 greater than x
    Parameters
    ----------
    x: (int or float) a number

    Returns
    -------
    int: the power of 2 greater than x
    """
⋮----
res = []
⋮----
def wrap(input: Union[np.ndarray, float], phase_range=(0, 2*np.pi))
⋮----
def linspace_step(start, stop, step)
⋮----
"""
    Compute a regular linspace_step distribution from start to stop values.

    =============== =========== ======================================
    **Parameters**    **Type**    **Description**
    *start*            scalar      the starting value of distribution
    *stop*             scalar      the stopping value of distribution
    *step*             scalar      the length of a distribution step
    =============== =========== ======================================

    Returns
    -------

    scalar array
        The computed distribution axis as an array.
    """
⋮----
Nsteps = int(np.ceil((stop - start) / step))
new_stop = start + (Nsteps - 1) * step
⋮----
tol = (new_stop + step - stop).magnitude
⋮----
tol = (new_stop + step - stop)
⋮----
def linspace_step_N(start, step, Npts)
⋮----
stop = (Npts - 1) * step + start
⋮----
def find_index(x, threshold: Union[Number, List[Number]]) -> List[tuple]
⋮----
"""find_index finds the index ix such that x(ix) is the closest from threshold

    Parameters
    ----------
    x : vector
    threshold : list of real numbers

    Returns
    -------
    out : list of 2-tuple containing ix,x[ix]
            out=[(ix0,xval0),(ix1,xval1),...]
    """
⋮----
threshold = [threshold]
out = []
⋮----
ix = int(np.argmin(np.abs(x - value)))
⋮----
def find_common_index(x: Iterable, y: Iterable, x0: Number, y0: Number) -> Tuple
⋮----
"""find the index in two vectors corresponding to x0 and y0"""
vals = x + 1j * y
val = x0 + 1j * y0
ind = int(np.argmin(np.abs(vals - val)))
⋮----
def gauss1D(x, x0, dx, n=1)
⋮----
"""
    compute the gaussian function along a vector x, centered in x0 and with a
    FWHM i intensity of dx. n=1 is for the standart gaussian while n>1 defines
    a hypergaussian

    Parameters
    ----------
    x: (ndarray) first axis of the 2D gaussian
    x0: (float) the central position of the gaussian
    dx: (float) :the FWHM of the gaussian
    n=1 : an integer to define hypergaussian, n=1 by default for regular gaussian
    Returns
    -------
    out : vector
      the value taken by the gaussian along x axis

    """
⋮----
out = np.exp(-2 * np.log(2) ** (1 / n) * (((x - x0) / dx)) ** (2 * n))
⋮----
def gauss2D(x, x0, dx, y, y0, dy, n=1, angle=0)
⋮----
"""
    compute the 2D gaussian function along a vector x, centered in x0 and with a
    FWHM in intensity of dx and smae along y axis. n=1 is for the standard gaussian while n>1 defines
    a hypergaussian. optionally rotate it by an angle in degree

    Parameters
    ----------
    x: (ndarray) first axis of the 2D gaussian
    x0: (float) the central position of the gaussian
    dx: (float) :the FWHM of the gaussian
    y: (ndarray) second axis of the 2D gaussian
    y0: (float) the central position of the gaussian
    dy: (float) :the FWHM of the gaussian
    n=1 : an integer to define hypergaussian, n=1 by default for regular gaussian
    angle: (float) a float to rotate main axes, in degree

    Returns
    -------
    out : ndarray 2 dimensions

    """
⋮----
data = np.transpose(np.outer(gauss1D(x, x0, dx, n), gauss1D(y, y0, dy, n)))
⋮----
theta = np.radians(angle)
⋮----
R = np.array(((c, -s), (s, c)))
⋮----
data = np.zeros((len(y), len(x)))
⋮----
rotatedvect = R.dot(np.array([xtmp, ytmp]))
⋮----
def rotate2D(origin:tuple = (0,0), point:tuple = (0,0), angle:float = 0)
⋮----
"""
    Rotate a point counterclockwise by a given angle around a given origin.

    The angle should be given in radians.
    Parameters
    ----------
    origin: (tuple) x,y coordinate from which to rotate
    point: (tuple) x,y coordinate of point to rotate
    angle: (float) a float to rotate main axes, in radian

    Returns
    -------
    out : (tuple) x,y coordinate of rotated point

    """
⋮----
qx = ox + np.cos(angle) * (px - ox) - np.sin(angle) * (py - oy)
qy = oy + np.sin(angle) * (px - ox) + np.cos(angle) * (py - oy)
⋮----
def ftAxis(Npts, omega_max)
⋮----
"""
    Given two numbers Npts,omega_max, return two vectors spanning the temporal
    and spectral range. They are related by Fourier Transform

    Parameters
    ----------
    Npts: (int)
      A number of points defining the length of both grids
    omega_max: (float)
      The maximum circular frequency in the spectral domain. its unit defines
      the temporal units. ex: omega_max in rad/fs implies time_grid in fs

    Returns
    -------
    omega_grid: (ndarray)
      The spectral axis of the FFT
    time_grid: (ndarray))
      The temporal axis of the FFT
    See Also
    --------
    ftAxis, ftAxis_time, ift, ft2, ift2
    """
⋮----
dT = 2 * np.pi / (2 * omega_max)
omega_grid = np.linspace(-omega_max, omega_max, Npts)
time_grid = dT * np.linspace(-(Npts - 1) / 2, (Npts - 1) / 2, Npts)
⋮----
def ftAxis_time(Npts, time_max)
⋮----
"""
    Given two numbers Npts,omega_max, return two vectors spanning the temporal
    and spectral range. They are related by Fourier Transform

    Parameters
    ----------
    Npts : number
      A number of points defining the length of both grids
    time_max : number
      The maximum tmporal window

    Returns
    -------
    omega_grid : vector
      The spectral axis of the FFT
    time_grid : vector
      The temporal axis of the FFT
    See Also
    --------
    ftAxis, ftAxis_time, ift, ft2, ift2
    """
⋮----
dT = time_max / Npts
omega_max = (Npts - 1) / 2 * 2 * np.pi / time_max
⋮----
def ft(x, dim=-1)
⋮----
"""
    Process the 1D fast fourier transform and swaps the axis to get coorect results using ftAxis
    Parameters
    ----------
    x: (ndarray) the array on which the FFT should be done
    dim: the axis over which is done the FFT (default is the last of the array)

    Returns
    -------
    See Also
    --------
    ftAxis, ftAxis_time, ift, ft2, ift2
    """
⋮----
out = np.fft.fftshift(np.fft.fft(np.fft.fftshift(x, axes=dim), axis=dim), axes=dim)
⋮----
def ift(x, dim=0)
⋮----
"""
    Process the inverse 1D fast fourier transform and swaps the axis to get correct results using ftAxis
    Parameters
    ----------
    x: (ndarray) the array on which the FFT should be done
    dim: the axis over which is done the FFT (default is the last of the array)

    Returns
    -------
    See Also
    --------
    ftAxis, ftAxis_time, ift, ft2, ift2
    """
⋮----
out = np.fft.fftshift(np.fft.ifft(np.fft.fftshift(x, axes=dim), axis=dim), axes=dim)
⋮----
def ft2(x, dim=(-2, -1))
⋮----
"""
    Process the 2D fast fourier transform and swaps the axis to get correct results using ftAxis
    Parameters
    ----------
    x: (ndarray) the array on which the FFT should be done
    dim: the axis over which is done the FFT (default is the last of the array)

    Returns
    -------
    See Also
    --------
    ftAxis, ftAxis_time, ift, ft2, ift2
    """
⋮----
out = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(x, axes=dim)), axes=dim)
⋮----
def ift2(x, dim=(-2, -1))
⋮----
"""
    Process the inverse 2D fast fourier transform and swaps the axis to get correct results using ftAxis
    Parameters
    ----------
    x: (ndarray) the array on which the FFT should be done
    dim: the axis (or a tuple of axes) over which is done the FFT (default is the last of the array)

    Returns
    -------
    See Also
    --------
    ftAxis, ftAxis_time, ift, ft2, ift2
    """
⋮----
out = np.fft.fftshift(np.fft.ifft2(np.fft.fftshift(x, axes=dim)), axes=dim)
⋮----
def flatten(xs)
⋮----
"""Flatten nested list"""
⋮----
class LSqEllipse
⋮----
def fit(self, data)
⋮----
"""Lest Squares fitting algorithm

        Theory taken from (*)
        Solving equation Sa=lCa. with a = |a b c d f g> and a1 = |a b c>
            a2 = |d f g>

        Args
        ----
        data (list:list:float): list of two lists containing the x and y data of the
            ellipse. of the form [[x1, x2, ..., xi],[y1, y2, ..., yi]]

        Returns
        ------
        coef (list): list of the coefficients describing an ellipse
           [a,b,c,d,f,g] corresponding to ax**2+2bxy+cy**2+2dx+2fy+g
        """
⋮----
# Quadratic part of design matrix [eqn. 15] from (*)
D1 = numpy.mat(numpy.vstack([x ** 2, x * y, y ** 2])).T
# Linear part of design matrix [eqn. 16] from (*)
D2 = numpy.mat(numpy.vstack([x, y, numpy.ones(len(x))])).T
⋮----
# forming scatter matrix [eqn. 17] from (*)
S1 = D1.T * D1
S2 = D1.T * D2
S3 = D2.T * D2
⋮----
# Constraint matrix [eqn. 18]
C1 = numpy.mat('0. 0. 2.; 0. -1. 0.; 2. 0. 0.')
⋮----
# Reduced scatter matrix [eqn. 29]
M = C1.I * (S1 - S2 * S3.I * S2.T)
⋮----
# M*|a b c >=l|a b c >. Find eigenvalues and eigenvectors from this equation [eqn. 28]
⋮----
# eigenvector must meet constraint 4ac - b^2 to be valid.
cond = 4 * numpy.multiply(evec[0, :], evec[2, :]) - numpy.power(evec[1, :], 2)
a1 = evec[:, numpy.nonzero(cond.A > 0)[1]]
⋮----
# |d f g> = -S3^(-1)*S2^(T)*|a b c> [eqn. 24]
a2 = -S3.I * S2.T * a1
⋮----
# eigenvectors |a b c d f g>
⋮----
def _save_parameters(self)
⋮----
"""finds the important parameters of the fitted ellipse

        Theory taken form http://mathworld.wolfram

        Args
        -----
        coef (list): list of the coefficients describing an ellipse
           [a,b,c,d,f,g] corresponding to ax**2+2bxy+cy**2+2dx+2fy+g

        Returns
        _______
        center (List): of the form [x0, y0]
        width (float): major axis
        height (float): minor axis
        phi (float): rotation of major axis form the x-axis in radians
        """
⋮----
# eigenvectors are the coefficients of an ellipse in general form
# a*x^2 + 2*b*x*y + c*y^2 + 2*d*x + 2*f*y + g = 0 [eqn. 15) from (**) or (***)
a = self.coef[0, 0]
b = self.coef[1, 0] / 2.
c = self.coef[2, 0]
d = self.coef[3, 0] / 2.
f = self.coef[4, 0] / 2.
g = self.coef[5, 0]
⋮----
# finding center of ellipse [eqn.19 and 20] from (**)
x0 = (c * d - b * f) / (b ** 2. - a * c)
y0 = (a * f - b * d) / (b ** 2. - a * c)
⋮----
# Find the semi-axes lengths [eqn. 21 and 22] from (**)
numerator = 2 * (a * f * f + c * d * d + g * b * b - 2 * b * d * f - a * c * g)
denominator1 = (b * b - a * c) * ((c - a) * numpy.sqrt(1 + 4 * b * b / ((a - c) * (a - c))) - (c + a))
denominator2 = (b * b - a * c) * ((a - c) * numpy.sqrt(1 + 4 * b * b / ((a - c) * (a - c))) - (c + a))
width = numpy.sqrt(numerator / denominator1)
height = numpy.sqrt(numerator / denominator2)
⋮----
# angle of counterclockwise rotation of major-axis of ellipse to x-axis [eqn. 23] from (**)
# or [eqn. 26] from (***).
phi = .5 * numpy.arctan((2. * b) / (a - c))
⋮----
@property
    def center(self)
⋮----
@property
    def width(self)
⋮----
@property
    def height(self)
⋮----
@property
    def phi(self)
⋮----
"""angle of counterclockwise rotation of major-axis of ellipse to x-axis
        [eqn. 23] from (**)
        """
⋮----
def parameters(self)
⋮----
def make_test_ellipse(center=[1, 1], width=1, height=.6, phi=3.14 / 5)
⋮----
"""Generate Elliptical data with noise

    Args
    ----
    center (list:float): (<x_location>, <y_location>)
    width (float): semimajor axis. Horizontal dimension of the ellipse (**)
    height (float): semiminor axis. Vertical dimension of the ellipse (**)
    phi (float:radians): tilt of the ellipse, the angle the semimajor axis
        makes with the x-axis

    Returns
    -------
    data (list:list:float): list of two lists containing the x and y data of the
        ellipse. of the form [[x1, x2, ..., xi],[y1, y2, ..., yi]]
    """
t = numpy.linspace(0, 2 * numpy.pi, 1000)
⋮----
ellipse_x = center[0] + width * numpy.cos(t) * numpy.cos(phi) - height * numpy.sin(t) * numpy.sin(
ellipse_y = center[1] + width * numpy.cos(t) * numpy.sin(phi) + height * numpy.sin(t) * numpy.cos(
</file>

<file path="src/pymodaq_utils/mysocket.py">
# -*- coding: utf-8 -*-
"""
Created the 26/10/2023

@author: Sebastien Weber
"""
⋮----
class Socket
⋮----
"""Custom Socket wrapping the built-in one and added functionalities to
    make sure message have been sent and received entirely"""
def __init__(self, socket: socket.socket = None)
⋮----
def __eq__(self, other_obj)
⋮----
other_obj = other_obj.socket
⋮----
@property
    def socket(self)
⋮----
def bind(self, *args, **kwargs)
⋮----
def listen(self, *args, **kwargs)
⋮----
def getsockname(self, *args, **kwargs)
⋮----
def accept(self)
⋮----
def connect(self, *args, **kwargs)
⋮----
def send(self, *args, **kwargs)
⋮----
def sendall(self, *args, **kwargs)
⋮----
def recv(self, *args, **kwargs)
⋮----
def close(self)
⋮----
def check_sended(self, data_bytes: bytes)
⋮----
"""
        Make sure all bytes are sent through the socket
        Parameters
        ----------
        data_bytes: bytes
        """
⋮----
sended = 0
⋮----
def check_received_length(self, length) -> bytes
⋮----
"""
        Make sure all bytes (length) that should be received are received through the socket

        Parameters
        ----------
        length: int
            The number of bytes to be read from the socket

        Returns
        -------
        bytes
        """
⋮----
mess_length = 0
data_bytes = b''
⋮----
data_bytes_tmp = self.socket.recv(4096)
⋮----
data_bytes_tmp = self.socket.recv(length - mess_length)
⋮----
# print(data_bytes)
⋮----
def get_first_nbytes(self, length: int) -> bytes
⋮----
""" Read the first N bytes from the socket

        Parameters
        ----------
        length: int
            The number of bytes to be read from the socket

        Returns
        -------
        bytes: the read bytes string
        """
</file>

<file path="src/pymodaq_utils/units.py">
# -*- coding: utf-8 -*-
"""
Created the 27/10/2022

@author: Sebastien Weber
"""
⋮----
Cb = 1.602176e-19  # coulomb
h = 6.626068e-34  # J.s
c = 2.997924586e8  # m.s-1
⋮----
def Enm2cmrel(E_nm, ref_wavelength=515)
⋮----
"""Converts energy in nm to cm-1 relative to a ref wavelength

    Parameters
    ----------
    E_nm: float
          photon energy in wavelength (nm)
    ref_wavelength: float
                    reference wavelength in nm from which calculate the photon relative energy

    Returns
    -------
    float
         photon energy in cm-1 relative to the ref wavelength

    Examples
    --------
    >>> Enm2cmrel(530, 515)
    549.551199853453
    """
⋮----
def Ecmrel2Enm(Ecmrel, ref_wavelength=515)
⋮----
"""Converts energy from cm-1 relative to a ref wavelength to an energy in wavelength (nm)

    Parameters
    ----------
    Ecmrel: float
            photon energy in cm-1
    ref_wavelength: float
                    reference wavelength in nm from which calculate the photon relative energy

    Returns
    -------
    float
         photon energy in nm

    Examples
    --------
    >>> Ecmrel2Enm(500, 515)
    528.6117526302285
    """
Ecm = 1 / (ref_wavelength * 1e-7) - Ecmrel
⋮----
def eV2nm(E_eV)
⋮----
"""Converts photon energy from electronvolt to wavelength in nm

    Parameters
    ----------
    E_eV: float
          Photon energy in eV

    Returns
    -------
    float
         photon energy in nm

    Examples
    --------
    >>> eV2nm(1.55)
    799.898112990037
    """
E_J = E_eV * Cb
E_freq = E_J / h
E_nm = c / E_freq * 1e9
⋮----
def nm2eV(E_nm)
⋮----
"""Converts photon energy from wavelength in nm to electronvolt

    Parameters
    ----------
    E_nm: float
          Photon energy in nm

    Returns
    -------
    float
         photon energy in eV

    Examples
    --------
    >>> nm2eV(800)
    1.549802593918197
    """
E_freq = c / E_nm * 1e9
E_J = E_freq * h
E_eV = E_J / Cb
⋮----
def E_J2eV(E_J)
⋮----
def eV2cm(E_eV)
⋮----
"""Converts photon energy from electronvolt to absolute cm-1

    Parameters
    ----------
    E_eV: float
          Photon energy in eV

    Returns
    -------
    float
         photon energy in cm-1

    Examples
    --------
    >>> eV2cm(0.07)
    564.5880342655984
    """
E_nm = eV2nm(E_eV)
E_cm = 1 / (E_nm * 1e-7)
⋮----
def nm2cm(E_nm)
⋮----
"""Converts photon energy from wavelength to absolute cm-1

        Parameters
        ----------
        E_nm: float
              Photon energy in nm

        Returns
        -------
        float
             photon energy in cm-1

        Examples
        --------
        >>> nm2cm(0.04)
        0.000025
        """
⋮----
def cm2nm(E_cm)
⋮----
"""Converts photon energy from absolute cm-1 to wavelength

            Parameters
            ----------
            E_cm: float
                  photon energy in cm-1

            Returns
            -------
            float
                 Photon energy in nm

            Examples
            --------
            >>> cm2nm(1e5)
            100
            """
⋮----
def eV2E_J(E_eV)
⋮----
def eV2radfs(E_eV)
⋮----
E_radfs = E_freq * 2 * np.pi / 1e15
⋮----
def l2w(x, speedlight=300)
⋮----
"""Converts photon energy in rad/fs to nm (and vice-versa)

    Parameters
    ----------
    x: float
       photon energy in wavelength or rad/fs
    speedlight: float, optional
                the speed of light, by default 300 nm/fs

    Returns
    -------
    float

    Examples
    --------
    >>> l2w(800)
    2.356194490192345
    >>> l2w(800,3e8)
    2356194.490192345
    """
y = 2 * np.pi * speedlight / x
</file>

<file path="src/pymodaq_utils/utils.py">
PackageNotFoundError = metadata.PackageNotFoundError  # for use elsewhere
⋮----
# for use elsewhere
⋮----
# from version 3.9 the cache decorator is available
⋮----
logger = logger_module.set_logger(logger_module.get_module_name(__file__))
⋮----
config = Config()
⋮----
class PlotColors
⋮----
def __init__(self, colors=config('plotting', 'plot_colors')[:])
⋮----
def copy(self)
⋮----
def remove(self, item)
⋮----
def __getitem__(self, item: int)
⋮----
def __len__(self)
⋮----
def __iter__(self)
⋮----
def __next__(self)
⋮----
def check_colors(self, colors: IterableType)
⋮----
@staticmethod
    def check_color(color: IterableType)
⋮----
plot_colors = PlotColors()
⋮----
def is_64bits()
⋮----
def timer(func)
⋮----
"""Print the runtime of the decorated function"""
⋮----
@functools.wraps(func)
    def wrapper_timer(*args, **kwargs)
⋮----
start_time = time.perf_counter()    # 1
value = func(*args, **kwargs)
end_time = time.perf_counter()      # 2
run_time = end_time - start_time    # 3
⋮----
def get_version(package_name='pymodaq')
⋮----
"""Obtain the package version using the importlib metadata module
    """
⋮----
class JsonConverter
⋮----
def __init__(self)
⋮----
@classmethod
    def trusted_types(cls)
⋮----
@classmethod
    def istrusted(cls, type_name)
⋮----
@classmethod
    def object2json(cls, obj)
⋮----
dic = dict(module=type(obj).__module__, type=type(obj).__name__, data=repr(obj))
⋮----
@classmethod
    def json2object(cls, jsonstring)
⋮----
dic = json.loads(jsonstring)
⋮----
else:                                               # pragma: no cover
⋮----
def capitalize(string, Nfirst=1)
⋮----
"""
    Returns same string but with first Nfirst letters upper
    Parameters
    ----------
    string: (str)
    Nfirst: (int)
    Returns
    -------
    str
    """
⋮----
def uncapitalize(string, Nfirst=1)
⋮----
def getLineInfo()
⋮----
"""get information about where the Exception has been triggered"""
tb = sys.exc_info()[2]
res = ''
⋮----
@SerializableFactory.register_decorator()
class ThreadCommand(SerializableBase)
⋮----
"""Generic object to pass info (command) and data (attribute) between thread or objects using signals

    Parameters
    ----------
    command: str
        The command to be analysed for further action
    attribute: any type
        the attribute related to the command. The actual type and value depend on the command and the situation
    attributes: deprecated, attribute should be used instead

    Attributes
    ----------
    command : str
        The command to be analysed for further action
    attribute : any type
        the attribute related to the command. The actual type and value depend on the command and the situation
    args: some variables in a list
    kwargs: some variables in a dict
    """
command: str
attribute: Any
args: list
kwargs: dict
⋮----
def __init__(self, command: str, attribute=None, attributes=None, args=(), kwargs: Optional[dict] = None)
⋮----
def __eq__(self, other: Any) -> bool
⋮----
@staticmethod
    def serialize(obj: "ThreadCommand") -> bytes:  # type: ignore[override]
⋮----
serialize_factory = SerializableFactory()
byte_string = b""
⋮----
@staticmethod
    def deserialize(bytes_str: bytes) -> Tuple["ThreadCommand", bytes]
⋮----
def __repr__(self)
⋮----
def ensure_ndarray(data)
⋮----
"""
    Make sure data is returned as a numpy array
    Parameters
    ----------
    data

    Returns
    -------
    ndarray
    """
⋮----
data = np.array(data)
⋮----
data = np.array([data])
⋮----
def recursive_find_files_extension(ini_path, ext, paths=[])
⋮----
found = False
⋮----
replacement = ''
⋮----
found = True
⋮----
def count_lines(ini_path, count=0, filters=['lextab', 'yacctab','pycache', 'pyc'])
⋮----
# if Path(ini_path).is_file():
#     with Path(ini_path).open('r') as f:
#         count += len(f.readlines())
#     return count
⋮----
count = count_lines(child, count)
⋮----
def remove_spaces(string)
⋮----
"""
    return a string without any white spaces in it
    Parameters
    ----------
    string

    Returns
    -------

    """
⋮----
def rint(x)
⋮----
"""
    almost same as numpy rint function but return an integer
    Parameters
    ----------
    x: (float or integer)

    Returns
    -------
    nearest integer
    """
⋮----
def elt_as_first_element(elt_list, match_word='Mock')
⋮----
ind_elt = 0
⋮----
ind_elt = ind
⋮----
plugin_match = elt_list[ind_elt]
⋮----
plugins = [plugin_match]
⋮----
plugins = []
⋮----
def elt_as_first_element_dicts(elt_list, match_word='Mock', key='name')
⋮----
def find_keys_from_val(dict_tmp: dict, val: object)
⋮----
"""Returns the keys from a dict if its value is matching val"""
⋮----
def find_object_if_matched_attr_name_val(obj, attr_name, attr_value)
⋮----
"""check if an attribute  key/value pair match in a given object

    Parameters
    ----------
    obj: object
    attr_name: str
        attribute name to look for in the object
    attr_value: object
        value to match

    Returns
    -------
    bool: True if the key/value pair has been found in dict_tmp

    """
⋮----
""" lookup within a list of objects. Look for the objects within the list which has the correct attribute name,
    value pair

    Parameters
    ----------
    objects: list
        list of objects
    attr_name: str
        attribute name to look for in the object
    attr_value: object
        value to match
    return_first: bool
        if True return the first objects found in the list else all the objects matching

    Returns
    -------
    list of tuple(object, int): object and index or list of object and indexes
    """
selection = []
obj = None
⋮----
obj = obj_tmp
⋮----
def find_dict_if_matched_key_val(dict_tmp, key, value)
⋮----
"""
    check if a key/value pair match in a given dictionary
    Parameters
    ----------
    dict_tmp: (dict) the dictionary to be tested
    key: (str) a key string to look for in dict_tmp
    value: (object) any python object

    Returns
    -------
    bool: True if the key/value pair has been found in dict_tmp

    """
⋮----
def find_dict_in_list_from_key_val(dicts, key, value, return_index=False)
⋮----
""" lookup within a list of dicts. Look for the dict within the list which has the correct key, value pair

    Parameters
    ----------
    dicts: (list) list of dictionnaries
    key: (str) specific key to look for in each dict
    value: value to match

    Returns
    -------
    dict: if found otherwise returns None
    """
⋮----
def get_entrypoints(group='pymodaq.plugins') -> List[metadata.EntryPoint]
⋮----
""" Get the list of modules defined from a group entry point

    Because of evolution in the package, one or another of the forms below may be deprecated.
    We start from the newer way down to the older

    Parameters
    ----------
    group: str
        the name of the group
    """
⋮----
discovered_entrypoints = metadata.entry_points(group=group)
⋮----
discovered_entrypoints = metadata.entry_points().select(group=group)
⋮----
discovered_entrypoints = metadata.entry_points().get(group, [])
if isinstance(discovered_entrypoints, tuple):  # API for python > 3.8
discovered_entrypoints = list(discovered_entrypoints)
⋮----
def check_vals_in_iterable(iterable1, iterable2)
⋮----
iterable1 = list(iterable1)  # so the assertion below is valid for any kind of iterable, list, tuple, ndarray...
iterable2 = list(iterable2)
⋮----
def caller_name(skip=2)
⋮----
"""Get a name of a caller in the format module.class.method

       `skip` specifies how many levels of stack to skip while getting caller
       name. skip=1 means "who calls me", skip=2 "who calls my caller" etc.

       An empty string is returned if skipped levels exceed stack height
    """
stack = inspect.stack()
start = 0 + skip
⋮----
parentframe = stack[start][0]
⋮----
name = []
module = inspect.getmodule(parentframe)
# `modname` can be None when frame is executed directly in console
# TODO(techtonik): consider using __main__
⋮----
# detect classname
⋮----
# I don't know any way to detect call from the object method
# XXX: there seems to be no way to detect static method call - it will
#      be just a function call
⋮----
codename = parentframe.f_code.co_name
if codename != '<module>':  # top level usually
name.append(codename)  # function or a method
⋮----
def zeros_aligned(n, align, dtype=np.uint32)
⋮----
"""
    Get aligned memory array wih alignment align.
    Parameters
    ----------
    n: (int) length in dtype bytes of memory
    align: (int) memory alignment
    dtype: (numpy.dtype) type of the stored memory elements

    Returns
    -------

    """
dtype = np.dtype(dtype)
nbytes = n * dtype.itemsize
buff = np.zeros(nbytes + align, dtype=np.uint8)
start_index = -buff.ctypes.data % align
⋮----
# ########################
# #File management
⋮----
def get_new_file_name(base_path=Path(config('data_saving', 'h5file', 'save_path')), base_name='tttr_data')
⋮----
base_path = Path(base_path)
⋮----
today = datetime.datetime.now()
⋮----
date = today.strftime('%Y%m%d')
year = today.strftime('%Y')
year_dir = base_path.joinpath(year)
⋮----
curr_dir = base_path.joinpath(year, date)
⋮----
files = []
⋮----
index = 0
⋮----
index = int(files[-1][-3:]) + 1
⋮----
file = f'{base_name}_{index:03d}'
⋮----
#paths = recursive_find_expr_in_files('C:\\Users\\weber\\Labo\\Programmes Python\\PyMoDAQ_Git', 'visa')
# for p in paths:
#     print(str(p))
# v = get_version()
# pass
#plugins = get_plugins()  # pragma: no cover
#extensions = get_extension()
#models = get_models()
#count = count_lines('C:\\Users\\weber\\Labo\\Programmes Python\\PyMoDAQ_Git\\pymodaq\src')
⋮----
# import license
# mit = license.find('MIT')
#
⋮----
# paths = recursive_find_expr_in_files(r'C:\Users\weber\Labo\Programmes Python\PyMoDAQ_Git',
#                                      exp="cfunc",
#                                      paths=[],
#                                      filters=['.git', '.idea', '__pycache__', 'build', 'egg', 'documentation',
#                                               '.tox',],
#                                      replace=False,
#                                      replace_str="pymodaq.utils")
⋮----
#get_version()
⋮----
# paths = recursive_find_files('C:\\Users\\weber\\Labo\\Programmes Python\\PyMoDAQ_Git',
#                      exp='VERSION', paths=[])
# import version
# for file in paths:
#     with open(str(file), 'r') as f:
#         v = version.Version(f.read())
#         v.minor += 1
#         v.patch = 0
#     with open(str(file), 'w') as f:
#         f.write(str(v))
⋮----
#         f.write(mit.render(name='Sebastien Weber', email='sebastien.weber@cemes.fr'))
</file>

<file path="src/pymodaq_utils/warnings.py">
def deprecation_msg(message, stacklevel=2)
⋮----
def user_warning(message, stacklevel=3)
</file>

<file path="tests/data/config_template.toml">
[style]
darkstyle = true
syntax_highlighting = "github-dark"
language = "English"
country = "UnitedStates"

[qtbackend]
backends = [ "pyqt5", "pyqt6", "pyside2", "pyside6",]
backend = "pyqt5"
</file>

<file path="tests/serialize/ser_utils_test.py">
class TestStaticClassMethods
⋮----
def test_int_to_bytes(self)
⋮----
afloat = 45.7
a_negative_integer = -56
⋮----
bytes_string = utils.int_to_bytes(int_obj)
⋮----
def test_str_to_bytes(self)
⋮----
MESSAGE = 'Hello World'
bytes_message = utils.str_to_bytes(MESSAGE)
⋮----
def test_str_len_to_bytes(self)
</file>

<file path="tests/serialize/serializer_legacy_test.py">
# -*- coding: utf-8 -*-
"""
Created the 22/10/2023

@author: Sebastien Weber
"""
⋮----
LABEL = 'A Label'
UNITS = 'units'
OFFSET = -20.4
SCALING = 0.22
SIZE = 20
DATA = OFFSET + SCALING * np.linspace(0, SIZE-1, SIZE)
⋮----
DATA0D = np.array([2.7])
DATA1D = np.arange(0, 10)
DATA2D = np.arange(0, 5*6).reshape((5, 6))
DATAND = np.arange(0, 5 * 6 * 3).reshape((5, 6, 3))
Nn0 = 10
Nn1 = 5
⋮----
def init_axis(data=None, index=0)
⋮----
data = DATA
⋮----
data = DATA2D
⋮----
errors = [np.random.random_sample(data.shape) for _ in range(Ndata)]
⋮----
errors = None
⋮----
@pytest.fixture()
def get_data()
⋮----
dat0D = init_data(DATA0D, 2, name='my0DData', source='raw', errors=True)
dat1D_calculated = init_data(DATA1D, 2, name='my1DDatacalculated',
dat1D_raw = init_data(DATA1D, 2, name='my1DDataraw', klass=data_mod.DataRaw,
dte = data_mod.DataToExport(name='toexport', data=[dat0D, dat1D_calculated, dat1D_raw])
⋮----
def test_string_serialization_deserialization()
⋮----
string = 'Hello World'
ser = Serializer(string)
⋮----
bytes_string = ser.string_serialization(string)
⋮----
deser = DeSerializer(bytes_string)
⋮----
def test_scalar_serialization_deserialization()
⋮----
scalars = [45.6, 67, -64, -56.8, 2+1j*56]
⋮----
ser = Serializer(scalar)
⋮----
def test_ndarray_serialization_deserialization()
⋮----
ndarrays = [np.array([12, 56, 78,]),
⋮----
ser = Serializer(ndarray)
⋮----
def test_object_type_serialization(get_data)
⋮----
dte = get_data
ser = Serializer()
objects = [dwa for dwa in dte]
⋮----
def test_axis_serialization_deserialization()
⋮----
axis = init_axis()
⋮----
ser = Serializer(axis)
⋮----
axis_deser = DeSerializer(ser.to_bytes()).axis_deserialization()
⋮----
ser = Serializer('bjkdbjk')
⋮----
@pytest.mark.parametrize('obj_list', (['hjk', 'jkgjg', 'lkhlkhl'],  # homogeneous string
[21, 34, -56, 56.7, 1+1j*99],  # homogeneous numbers
⋮----
[-45, -67, -87654]])],  # homogeneous ndarrays
[init_axis(), init_axis()],  # homogeneous axis
[init_data(), init_data(), init_data()],  # homogeneous dwa
⋮----
init_axis(), True, 23, False]))  # inhomogeneous
def test_list_serialization_deserialization(get_data, obj_list)
⋮----
ser = Serializer(obj_list)
list_back = DeSerializer(ser.to_bytes()).list_deserialization()
⋮----
def test_dwa_serialization_deserialization(get_data)
⋮----
ser = Serializer(dwa)
⋮----
dwa_back = DeSerializer(ser.to_bytes()).dwa_deserialization()
⋮----
def test_dte_serialization(get_data)
⋮----
ser = Serializer(dte)
⋮----
dte_back = DeSerializer(ser.to_bytes()).dte_deserialization()
⋮----
def test_base_64_de_serialization(get_data: DataToExport)
⋮----
serialized_string = ser.to_b64_string()
⋮----
deser: DeSerializer = DeSerializer.from_b64_string(serialized_string)
dte_back = deser.dte_deserialization()
⋮----
class TestObjectSerializationDeSerialization
⋮----
# (123, b'\x00\x00\x00\x06scalar\x00\x00\x00\x03<i4\x00\x00\x00\x04{\x00\x00\x00'),  # it varies on different test machines
⋮----
def test_serialization(self, obj, serialized)
⋮----
def test_array(self)
⋮----
obj = np.array([[0.1, 0.5], [5, 7], [8, 9]])
serialized = (b'\x00\x00\x00R\x00\x00\x00\x07ndarray\x00\x00\x00\x03<f8\x00\x00\x000\x00'
⋮----
def test_dwa(self, get_data)
⋮----
def test_axis(self, get_data)
⋮----
def test_list(self, get_data)
⋮----
obj = [True, 12.4, dte[0], [False, 78]]
⋮----
def test_dte(self, get_data)
⋮----
dte_in = get_data
⋮----
serialized = Serializer().type_and_object_serialization(dte_in)
dte_out = DeSerializer(serialized).type_and_object_deserialization()
</file>

<file path="tests/serialize/serializer_test.py">
ser_factory = SerializableFactory()
⋮----
LABEL = 'A Label'
UNITS = 'mm'
OFFSET = -20.4
SCALING = 0.22
SIZE = 20
DATA = OFFSET + SCALING * np.linspace(0, SIZE-1, SIZE)
⋮----
DATA0D = np.array([2.7])
DATA1D = np.arange(0, 10)
DATA2D = np.arange(0, 5*6).reshape((5, 6))
DATAND = np.arange(0, 5 * 6 * 3).reshape((5, 6, 3))
Nn0 = 10
Nn1 = 5
⋮----
def test_none_serialization()
⋮----
obj_type = "NoneType"
⋮----
def test_string_serialization()
⋮----
s = 'ert'
obj_type = 'str'
⋮----
def test_bytes_serialization()
⋮----
b = b'kjlksjdf'
obj_type = 'bytes'
⋮----
def test_scalar_serialization()
⋮----
s = 23
obj_type = 'int'
⋮----
s = -3.8
obj_type = 'float'
⋮----
s = 4 - 2.5j
obj_type = 'complex'
⋮----
def test_bool_serialization()
⋮----
s = True
obj_type = 'bool'
⋮----
s = False
⋮----
def test_ndarray_serialization_deserialization()
⋮----
ndarrays = [np.array([12, 56, 78,]),
⋮----
ser = NdSD.serialize(ndarray)
⋮----
@pytest.mark.parametrize('obj_list', (['hjk', 'jkgjg', 'lkhlkhl'],  # homogeneous string
[21, 34, -56, 56.7, 1+1j*99],  # homogeneous numbers
⋮----
np.array([[45, 67, 87654], [-45, -67, -87654]])],  # homogeneous ndarrays
['hjk', 23, 34.7, np.array([1, 2, 3])],  # inhomogeneous list
⋮----
def test_list_serialization_deserialization(obj_list)
⋮----
ser = LSD.serialize(obj_list)
⋮----
list_back = LSD.deserialize(ser)[0]
</file>

<file path="tests/serialize/socket_test.py">
class MockPythonSocket:  # pragma: no cover
⋮----
def __init__(self)
⋮----
def bind(self, *args, **kwargs)
⋮----
arg = args[0]
⋮----
def listen(self, *args)
⋮----
def accept(self)
⋮----
def getsockname(self)
⋮----
def connect(self, *args, **kwargs)
⋮----
def send(self, *args, **kwargs)
⋮----
def sendall(self, *args, **kwargs)
⋮----
def recv(self, length, **kwargs)
⋮----
bytes_string = self._send[0:length]
⋮----
def close(self)
⋮----
def setsockopt(self, *args, **kwargs)
⋮----
class TestSocket
⋮----
def test_init(self)
⋮----
test_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
test_Socket = Socket(test_socket)
⋮----
def test_base_fun(self)
⋮----
test_socket = MockPythonSocket()
⋮----
def test_check_sended(self)
⋮----
test_Socket = Socket(MockPythonSocket())
⋮----
def test_check_received_length(self)
</file>

<file path="tests/abstract_test.py">
# -*- coding: utf-8 -*-
"""
Created the 21/11/2022

@author: Sebastien Weber
"""
⋮----
class AbstractFoo(metaclass=ABCMeta)
⋮----
@abstract_attribute
    def bar(self)
⋮----
class Foo(AbstractFoo)
⋮----
def __init__(self)
⋮----
class BadFoo(AbstractFoo)
⋮----
class Base(metaclass=ABCMeta)
⋮----
aa = abstract_attribute()
⋮----
class RealClass(Base)
⋮----
aa = 'mandatory_attribute'
⋮----
class RealBadClass(Base)
⋮----
def test_abstract_attribute()
⋮----
Foo()  # ok
⋮----
def test_abstract_class_attribute()
⋮----
s = RealBadClass()
</file>

<file path="tests/array_manipulation_test.py">
def test_random_step()
⋮----
pos_array = array.random_step(0, 10, 1)
⋮----
neg_array = array.random_step(0, -10, -1)
⋮----
def test_linspace_this_vect()
⋮----
test_x = [0.0, 1.1, 2.2, 3.3, 10]
linear_x = array.linspace_this_vect(test_x)
result_x = [0, 2.5, 5, 7.5, 10]
⋮----
test_y = [0.0, 0.55, 1.1, 1.65, 5]
⋮----
result_y = [0, 1.25, 2.5, 3.75, 5]
⋮----
linear_dim = array.linspace_this_vect(test_x, Npts = 11)
result_dim = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
⋮----
def test_find_index()
⋮----
test_array = np.array([1, 2, 3, 4, 5, 10, 20, 30, 40, 200, 2000])
values = [3.25, 27, 39, 1000, 5000, -10]
indexes_found = array.find_index(test_array, values)
results = [(2, 3), (7, 30), (8, 40), (9, 200), (10, 2000), (0, 1)]
⋮----
value = 15.5
index_found = array.find_index(test_array, value)
result = [(6, 20)]
⋮----
def test_find_rising_edges()
⋮----
test_x = np.array([3, 2, 1, 2, 3, 4, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 6, 5])
indexes_found = array.find_rising_edges(test_x, 1.1)
results = [([2, 12], np.array([1, 1]))]
⋮----
indexes_found = array.find_rising_edges(test_x, [1.1, 5.5])
results = [([2, 12], np.array([1, 1])), ([15], np.array([4]))]
⋮----
def test_crop_vector_to_axis()
⋮----
test_x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
test_V = np.array([12.5, 13, 12, 11, 9.8, 9.5, 9, 10.1, 10.3, 10.8, 11])
⋮----
result_x = np.array([3, 4, 5, 6, 7])
result_V = np.array([12, 11, 9.8, 9.5, 9])
⋮----
def test_rescale()
⋮----
test_x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
rescaled_x = array.rescale(test_x)
result = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])
⋮----
rescaled_x = array.rescale(test_x, [1, 0])
result = np.flip(result)
⋮----
rescaled_x = array.rescale(test_x, [0, 5])
result = np.array([0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5])
⋮----
def test_marginals()
⋮----
test_x = np.array([[1, 2, 3], [0.1, 0.2, 0.3]])
marginalised = array.marginals(test_x)
result = tuple([np.array([6, 0.6]), np.array([1.1, 2.2, 3.3])])
⋮----
marginalised = array.marginals(test_x, axes=[2])
⋮----
marginalised = array.marginals(test_x, normalize=True)
result = tuple([np.array([1, 0]), np.array([0, 0.5, 1])])
⋮----
def test_find()
⋮----
test_x = np.array([1, 2, 3, -1, 4])
is_positive = lambda x: x > 0
⋮----
test_x = np.array([-1, -2, -3, -4, -5])
⋮----
is_negative = lambda x: x < 0
⋮----
def test_arglimit()
⋮----
test_x = np.array([1, 2, 3, 4, 5, 6])
⋮----
test_x = np.array([1e4, 1e3, 100, 10, 1, 0.1, 0.01])
⋮----
def test_limit()
⋮----
test_y = np.array([1e4, 1e3, 100, 10, 1, 0.1])
⋮----
def test_crop_array_to_axis()
⋮----
test_x = np.array([1, 2, 3, 4])
test_y = np.array([0.1, 0.2, 0.3, 0.4])
test_M = np.array([[0.1, 0.2, 0.3, 0.4],
cropbox = np.array([2, 4, 0.1, 0.3])
cropped = array.crop_array_to_axis(test_x, test_y, test_M, cropbox)
result = tuple([test_x[1:], test_y[:3], test_M[:3, 1:]])
⋮----
cropbox = np.array([4, 2, 0.3, 0.1])
⋮----
def test_interp1D()
⋮----
x = np.linspace(1, 10, 10)
xlin = np.linspace(10, 1, 10)
M = np.linspace(x, x + 90, 10)
result = array.interp1D(x, M, xlin, axis=0)
expected = np.linspace(x + 90, x, 10)
⋮----
result = array.interp1D(x, M, xlin, axis=1)
expected = np.linspace(xlin, xlin + 90, 10)
⋮----
def test_linspace_this_image()
⋮----
result = array.linspace_this_image(x, M)
⋮----
y = np.linspace(10, 1, 10)
result = array.linspace_this_image(y, M, axis=0)
expected = np.append([x], np.linspace(x + 90, x + 90, 9), axis=0)
⋮----
def test_max_ind()
⋮----
test_x = [10, 17, 13, 17.2, 4, -30]
⋮----
test_x = [[10, 17, 13, 17.2, 4, -30], [1, 7, 3, 9, -4, -12]]
max_ind = array.max_ind(test_x, axis=0)
result = tuple([np.array([0, 0, 0, 0, 0, 1]), np.array([10, 17, 13, 17.2, 4, -12])])
⋮----
max_ind = array.max_ind(test_x, axis=1)
result = tuple([np.array([3, 3]), np.array([17.2, 9])])
⋮----
def test_min_ind()
⋮----
min_ind = array.min_ind(test_x, axis=0)
result = tuple([np.array([1, 1, 1, 1, 1, 0]), np.array([1, 7, 3, 9, -4, -30])])
⋮----
min_ind = array.min_ind(test_x, axis=1)
result = tuple([np.array([5, 5]), np.array([-30, -12])])
</file>

<file path="tests/config_test.py">
TOML_DICT = dict(
⋮----
def create_toml(path: Path)
⋮----
def test_replace_extension()
⋮----
test_name = 'config_test'
⋮----
@pytest.mark.parametrize('user', [False, True])
def test_get_set_local_dir(user)
⋮----
local_path = config_mod.get_set_local_dir(user=user)
⋮----
class TestGetSet
⋮----
def test_get_set_config_path(self)
⋮----
local_path = config_mod.get_set_local_dir()
config_path = config_mod.get_set_config_dir()
⋮----
class TestCopy
⋮----
def test_copy_default(self)
⋮----
test_name = 'config'
dest_file = config_mod.copy_template_config()
dest_path = config_mod.get_set_local_dir()
⋮----
def test_copy_source(self, tmp_path)
⋮----
suffix = '.ini'
⋮----
template_path = tmp_path.joinpath('template.toml')
⋮----
dest_file = config_mod.copy_template_config(test_name + suffix, source_path=template_path)
⋮----
def test_copy_dest(self, tmp_path)
⋮----
dest_name = 'dest'
dest_path = tmp_path.joinpath(dest_name)
⋮----
dest_file = config_mod.copy_template_config(test_name, source_path=template_path, dest_path=dest_path)
⋮----
def test_load_system_config(tmp_path)
⋮----
system_file = config_mod.get_set_local_dir().joinpath(test_name + '.toml')
user_file = config_mod.get_set_local_dir(True).joinpath(test_name + '.toml')
⋮----
dest_file = config_mod.copy_template_config(test_name, source_path=template_path)
config_dict = config_mod.load_system_config_and_update_from_user(test_name)
⋮----
user_path = config_mod.get_set_local_dir(user=True).joinpath(
user_dict = dict(other='456')
⋮----
# modifying nested dicts
⋮----
def test_check_config()
⋮----
dict1 = {'name': 'test', 'status': True}
dict2 = {'name': 'test_2', 'status': False}
dict3 = {'status': None}
⋮----
class TestConfig
⋮----
def test_init(self)
⋮----
def test_call(self)
⋮----
config = config_mod.Config()
⋮----
def test_get_item(self)
⋮----
def test_set_item(self)
⋮----
def test_get_children(self)
⋮----
children = config.get_children('data_saving')
⋮----
class Config(config_mod.BaseConfig)
⋮----
config_name = 'custom_config_tested'
config_template_path = Path(__file__).parent.joinpath('data/config_template.toml')
⋮----
def test_custom_config()
⋮----
config = Config()
config_dict = toml.load(config.config_template_path)
⋮----
def test_nested_update_from_user(tmp_path)
⋮----
""" make sure the user defined entry within a nested config is loaded but that the other entries are also loaded
     from the system wide config file"""
⋮----
create_toml(template_path)  # creates a system wide config using TOML_DICT
⋮----
user_dict = dict(
⋮----
toml.dump(user_dict, f)  # creates a user config file with one entry of the nested config updated
⋮----
assert 'stop' in config_dict['scan']['scan1d']  # making sure the entry that is not in the user is still present
⋮----
class CustomConfig(config_mod.BaseConfig)
⋮----
"""Main class to deal with configuration values for this plugin"""
config_template_path = None
config_name = f"custom_settings"
⋮----
def test_recursive_iterable_flattening()
⋮----
flattened = config_mod.recursive_iterable_flattening([1, 3, ['klm', 4], 'poi', [1, [[1, 2], 'uio']]])
⋮----
def test_required_config_entries()
</file>

<file path="tests/enums_test.py">
class Enum(enums.BaseEnum)
⋮----
name1 = 45
name2 = 'str'
name3 = -2
⋮----
class Enumbis(enums.BaseEnum)
⋮----
name4 = 45
name5 = 'str'
name6 = -2
⋮----
def test_base_enum()
⋮----
txt = 'name2'
myenum = Enum[txt]
⋮----
def test_enum_checker()
⋮----
def test_enum_to_dict()
</file>

<file path="tests/environment_test.py">
POSSIBLE_VENV_VARIABLES = ['VIRTUAL_ENV', 'CONDA_DEFAULT_ENV', 'PYENV_VERSION', 'TOX_ENV_NAME']
class TestGuessVirtualEnvironment
⋮----
@pytest.mark.parametrize("var", POSSIBLE_VENV_VARIABLES)
    def test_from_environment_var(self, monkeypatch, var)
⋮----
venv_name = "if_your_environment_is_called_like_that_you_should_probably_change_it"
⋮----
# set one of the possible environment variable to the var name value
# and remove the others
⋮----
def test_from_prefix(self, monkeypatch)
⋮----
def test_unknown(self, monkeypatch)
⋮----
class TestPythonEnvironment
⋮----
def test_empty_init(self)
⋮----
e = PythonEnvironment()
⋮----
def test_equality(self)
⋮----
package_list = ['package_one==0.0.1', 'package_two==0.0.2', 'package_three==0.0.3', 'package_four==0.0.4', 'package_five==0.0.5']
e1 = PythonEnvironment()
⋮----
e2 = PythonEnvironment()
⋮----
def test_different(self)
⋮----
def test_freeze(self)
⋮----
e1 = PythonEnvironment.from_freeze()
e2 = PythonEnvironment.from_freeze()
</file>

<file path="tests/logger_test.py">
# -*- coding: utf-8 -*-
"""
Created the 28/10/2022

@author: Sebastien Weber
"""
⋮----
def test_get_module_name()
⋮----
config_path = config_mod.get_set_config_dir()
⋮----
def test_get_base_logger()
⋮----
logger = logger_mod.set_logger('random_name')
</file>

<file path="tests/math_utils_test.py">
# -*- coding: utf-8 -*-
"""
Created the 08/03/2022

@author: Sebastien Weber
"""
⋮----
class TestMath
⋮----
def test_my_moment(self)
⋮----
x = mutils.linspace_step(0, 100, 1)
y = mutils.gauss1D(x, 42.321,
⋮----
13.5)  # relation between dx in the gauss1D and in the moment is np.sqrt(4*np.log(2))
⋮----
def test_normalize(self)
⋮----
ind = np.random.randint(1, 100 + 1)
⋮----
def test_odd_even(self)
⋮----
def test_greater2n(self)
⋮----
def test_linspace_step(self)
⋮----
def test_linspace_step_N(self)
⋮----
START = -1.
STEP = 0.25
LENGTH = 5
data = mutils.linspace_step_N(START, STEP, LENGTH)
⋮----
def test_find_index(self):  # get closest value and index
⋮----
x = mutils.linspace_step(1.0, -1, -0.13)
⋮----
def test_find_common_index(self)
⋮----
IND_TEST = np.random.randint(0, 99, 1)[0]
x = np.random.random(100)
y = np.random.rand(100)
x0 = x[IND_TEST]
y0 = y[IND_TEST]
⋮----
def test_gauss1D(self)
⋮----
x0 = -0.55
dx = 0.1
n = 1
⋮----
def test_gauss2D(self)
⋮----
x = mutils.linspace_step(-1.0, 1, 0.1)
⋮----
y = mutils.linspace_step(-2.0, -1, 0.1)
y0 = -1.55
dy = 0.2
⋮----
def test_ftAxis(self)
⋮----
omega_max = units.l2w(800)
Npts = 1024
⋮----
def test_ftAxis_time(self)
⋮----
time_max = 10000  # fs
⋮----
def test_ft(self)
⋮----
omega_max = units.l2w(300)
omega0 = units.l2w(800)
Npts = 2 ** 10
⋮----
signal_temp = np.sin(omega0 * time_grid) * mutils.gauss1D(time_grid, 0, 100, 1)
signal_omega = mutils.ft(signal_temp)
⋮----
def test_ift(self)
⋮----
def test_ft2(self)
⋮----
x = np.array([np.linspace(1, 10, 10), np.linspace(10, 1, 10)])
⋮----
def test_ift2(self)
⋮----
def test_rotate2D(self)
⋮----
accuracy = 10 # Rouding precision
x,y = (0,0) # Point to rotate
ox,oy = (1,1) # Origin
angle = np.pi/2 # Angle
⋮----
angle = np.pi
⋮----
def test_wrap(self)
⋮----
phase_array = 10 * (np.random.rand(10)-0.5) * np.pi
</file>

<file path="tests/units_test.py">
# -*- coding: utf-8 -*-
"""
Created the 28/10/2022

@author: Sebastien Weber
"""
⋮----
class TestUnits
⋮----
def test_Enm2cmrel(self)
⋮----
def test_Ecmrel2Enm(self)
⋮----
def test_eV2nm(self)
⋮----
def test_nm2eV(self)
⋮----
def test_E_J2eV(self)
⋮----
def test_eV2cm(self)
⋮----
def test_nm2cm(self)
⋮----
def test_cm2nm(self)
⋮----
def test_eV2E_J(self)
⋮----
def test_eV2radfs(self)
⋮----
def test_l2w(self)
</file>

<file path="tests/utils_test.py">
class MockEntryPoints
⋮----
def __init__(self, value)
⋮----
class MockObject
⋮----
def __init__(self, **kwargs)
⋮----
def test_get_version()
⋮----
version = utils.get_version('pymodaq_utils')
⋮----
class TestJsonConverter
⋮----
def test_object2json(self)
⋮----
conv = utils.JsonConverter()
⋮----
d = datetime.datetime(year=2020, month=5, day=24, hour=10, minute=52, second=55)
date = d.date()
time = d.time()
dstring = '{"module": "datetime", "type": "datetime", "data": "datetime.datetime(2020, 5, 24, 10, 52, 55)"}'
datestring = '{"module": "datetime", "type": "date", "data": "datetime.date(2020, 5, 24)"}'
timestring = '{"module": "datetime", "type": "time", "data": "datetime.time(10, 52, 55)"}'
⋮----
class TestString
⋮----
def test_capitalize(self)
⋮----
string = 'abcdef'
⋮----
def test_uncapitalize(self)
⋮----
string = 'ABCDef'
⋮----
def test_getLineInfo()
⋮----
def test_ThreadCommand()
⋮----
command = 'abc'
attributes = [1, 3]
threadcomm = utils.ThreadCommand(command, attributes)
⋮----
def test_ThreadCommand_eq(other, expected)
⋮----
base = utils.ThreadCommand('test', [1, 2])
⋮----
class Test_ThreadCommand_Serialization
⋮----
test_pairs = (
ids = ("with int", "with None attribute")
⋮----
@pytest.mark.parametrize("test_pair", test_pairs, ids=ids)
    def test_serialization(self, test_pair)
⋮----
serialized = SerializableFactory().get_apply_serializer(expected_tc)
⋮----
@pytest.mark.parametrize("test_pair", test_pairs, ids=ids)
    def test_deserialization(self, test_pair)
⋮----
deser = SerializableFactory().get_apply_deserializer(expected_bytes)
⋮----
def test_recursive_find_files_extension()
⋮----
path = Path(os.path.dirname(os.path.realpath(__file__)))
⋮----
ext = 'py'
⋮----
def test_recursive_find_exp_in_files()
⋮----
exp = 'import pytest'
⋮----
def test_remove_spaces()
⋮----
def test_rint()
⋮----
x1 = 15.49
x2 = 15.51
y1 = utils.rint(x1)
y2 = utils.rint(x2)
⋮----
def test_elt_as_first_element()
⋮----
elts = ['test', 'tyuio', 'Mock', 'test2']
elts_sorted = utils.elt_as_first_element(elts[:])
⋮----
elts_sorted = utils.elt_as_first_element(elts[:], elts[1])
⋮----
def test_elt_as_first_element_dicts()
⋮----
dict1 = {"module": "Empty", "name": "1D"}
dict2 = {"module": "Empty", "name": "Mock"}
elts_sorted = utils.elt_as_first_element_dicts([dict1, dict2])
⋮----
def test_check_vals_in_iterable()
⋮----
def test_zeros_aligned()
⋮----
# just one example...
align = 64
data = utils.zeros_aligned(1230, align, np.uint32)
⋮----
def test_get_new_file_name(tmp_path)
⋮----
base_name = 'tttr_data'
⋮----
today = datetime.datetime.now()
date = today.strftime('%Y%m%d')
year = today.strftime('%Y')
⋮----
base_name = 'anotherbasename'
⋮----
file_path = str(tmp_path)
⋮----
class TestFindInIterable
⋮----
def test_find_dict_if_matched_key_val(self)
⋮----
dict_tmp = {1: 'abc', 2: 'def'}
⋮----
def test_find_dict_in_list_from_key_val(self)
⋮----
dict_tmp_1 = {1: 'abc', 2: 'def'}
dict_tmp_2 = {1: 'def', 2: 'abc'}
dict_tmp_3 = {'abc': 1, 'def': 2}
dicts = [dict_tmp_1, dict_tmp_2, dict_tmp_3]
⋮----
def test_find_object_if_matched_attr_name_val(self)
⋮----
obj = MockObject(attr1=12, attr2='ghj')
⋮----
def find_objects_in_list_from_attr_name_val(self)
⋮----
objects = [MockObject(attr1=elt1, attr2=elt2) for elt1, elt2 in zip(['abc', 'abc', 'bgf'], [12, 45, 45])]
⋮----
selection = utils.find_objects_in_list_from_attr_name_val(objects, 'attr1', 'abc', return_first=False)
⋮----
selection = utils.find_objects_in_list_from_attr_name_val(objects, 'attr2', 45, return_first=False)
⋮----
class TestPlotColor
⋮----
def test_iterable(self)
⋮----
pcolor = utils.PlotColors((0, 0, 0))
⋮----
def test_non_integer(self)
⋮----
pcolor = utils.PlotColors([(0, 0., 0)])
⋮----
def test_non_8bits(self)
⋮----
pcolor = utils.PlotColors([(0, 256, 0)])
⋮----
def test_negative(self)
⋮----
pcolor = utils.PlotColors([(0, -5, 0)])
⋮----
def test_get_item(self)
⋮----
pcolor = utils.PlotColors()
⋮----
item = random.randrange(100)
color = pcolor[item]
⋮----
def test_len(self)
⋮----
N = random.randrange(10) + 1
pcolor = utils.PlotColors([(0, 0, 0) for _ in range(N)])
⋮----
def test_iter(self)
⋮----
colors = [color for color in pcolor]
</file>

<file path=".gitattributes">
# Auto detect text files and perform LF normalization
* text=auto
</file>

<file path=".gitignore">
# Compiled python modules.
*.pyc

# Byte-compiled / optimized / DLL files
__pycache__/


*.py[cod]
*$py.class

# C extensions
*.so
.idea/*

# Distribution / packaging
.Python
documentation/_*
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

*.idea

# Translations
*.mo
*.pot


# Django stuff:
*.log
local_settings.py
db.sqlite3

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# VS code project settings
.vscode/*

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.idea/workspace.xml

*.iml


.tox
*.h5
!data.h5

*yacctab.py
*lextab.py
</file>

<file path="CITATION.cff">
cff-version: 1.2.0
message: "If you use this software, please cite it as below."
authors:
- family-names: "Weber"
  given-names: "Sébastien J."
  orcid: "https://orcid.org/0000-0001-8531-5551"
title: "PyMoDAQ: An open-source Python-based software for modular data acquisition"
version: 4.2.4
doi: 10.1063/5.0032116
date-released: 2024-07-15
url: "https://github.com/PyMoDAQ/PyMoDAQ"
preferred-citation:
  type: article
  authors:
  - family-names: "Weber"
    given-names: "Sébastien J."
    orcid: "https://orcid.org/0000-0001-8531-5551"
  doi: "10.1063/5.0032116"
  journal: "Review of Scientific Instruments"
  month: 4
  start: 045104 # First page number
  end: 11 # Last page number
  title: "PyMoDAQ: An open-source Python-based software for modular data acquisition"
  issue: 4
  volume: 92
  year: 2021
</file>

<file path="LICENSE">
The MIT License (MIT)

Copyright (c) 2021 Sebastien Weber <sebastien.weber@cemes.fr>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
</file>

<file path="MANIFEST.in">
graft src
include README.rst
include LICENSE
include src/pymodaq/ressources/VERSION
recursive-include src/pymodaq/ressources *.toml *.xml
recursive-include src/pymodaq *.png *.ico
recursive-exclude src/pymodaq *.pyc
</file>

<file path="pyproject.toml">
[build-system]
requires = ["hatchling>=1.9.0", "hatch-vcs"]
build-backend = "hatchling.build"

[project]
name = "pymodaq_utils"
dynamic = [
    "version",
]
description = "Modular Data Acquisition with Python"
readme = "README.rst"
license = { file="LICENSE" }
requires-python = ">=3.8"
authors = [
    { name = "Sébastien Weber", email = "sebastien.weber@cemes.fr" },
]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Environment :: Other Environment",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Natural Language :: English",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Human Machine Interfaces",
    "Topic :: Scientific/Engineering :: Visualization",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Software Development :: User Interfaces",
]
dependencies = [
    "multipledispatch",
    "numpy < 2.0.0",
    "packaging",
    "pint",
    "python-dateutil",
    "scipy",
    "setuptools>=60",
    "toml",
    "strenum; python_version<\"3.11\"",
]

[project.optional-dependencies]
dev = [
    "hatch", 
    "flake8",
    "h5py",
    "pytest",
    "pytest-cov",
    "pytest-xdist",
]

[project.scripts]

[project.urls]
Homepage = "http://pymodaq.cnrs.fr"
Source = "https://github.com/PyMoDAQ/pymodaq_utils"
Tracker = "https://github.com/PyMoDAQ/pymodaq_utils/issues"

[tool.hatch.version]
source = "vcs"
fallback-version = "0.0.9"

[tool.hatch.build.targets.sdist]
include = [
    "/src",
]

[tool.coverage.run]
omit = [
    "*/resources/*"
]
</file>

<file path="README.rst">
PyMoDAQ Utils
#############

.. image:: https://img.shields.io/pypi/v/pymodaq_utils.svg
   :target: https://pypi.org/project/pymodaq_utils/
   :alt: Latest Version

.. image:: https://readthedocs.org/projects/pymodaq/badge/?version=latest
   :target: https://pymodaq.readthedocs.io/en/stable/?badge=latest
   :alt: Documentation Status

.. image:: https://codecov.io/gh/PyMoDAQ/pymodaq_utils/branch/0.0.x_dev/graph/badge.svg?token=IyhqsXIhjt 
 :target: https://codecov.io/gh/PyMoDAQ/pymodaq_utils

+-------------+-------------+---------------+
|             | Linux       | Windows       |
+=============+=============+===============+
| Python 3.9  | |39-linux|  | |39-windows|  |
+-------------+-------------+---------------+
| Python 3.10 | |310-linux| | |310-windows| |
+-------------+-------------+---------------+
| Python 3.11 | |311-linux| | |311-windows| |
+-------------+-------------+---------------+
| Python 3.12 | |312-linux| | |312-windows| |
+-------------+-------------+---------------+





.. |39-linux| image:: https://raw.githubusercontent.com/PyMoDAQ/pymodaq_utils/badges/0.0.x_dev/tests_Linux_3.9.svg
    :target: https://github.com/PyMoDAQ/pymodaq_utils/actions/workflows/tests.yml

.. |310-linux| image:: https://raw.githubusercontent.com/PyMoDAQ/pymodaq_utils/badges/0.0.x_dev/tests_Linux_3.10.svg
    :target: https://github.com/PyMoDAQ/pymodaq_utils/actions/workflows/tests.yml

.. |311-linux| image:: https://raw.githubusercontent.com/PyMoDAQ/pymodaq_utils/badges/0.0.x_dev/tests_Linux_3.11.svg
    :target: https://github.com/PyMoDAQ/pymodaq_utils/actions/workflows/tests.yml

.. |312-linux| image:: https://raw.githubusercontent.com/PyMoDAQ/pymodaq_utils/badges/0.0.x_dev/tests_Linux_3.12.svg
    :target: https://github.com/PyMoDAQ/pymodaq_utils/actions/workflows/tests.yml

.. |39-windows| image:: https://raw.githubusercontent.com/PyMoDAQ/pymodaq_utils/badges/0.0.x_dev/tests_Windows_3.9.svg
    :target: https://github.com/PyMoDAQ/pymodaq_utils/actions/workflows/tests.yml

.. |310-windows| image:: https://raw.githubusercontent.com/PyMoDAQ/pymodaq_utils/badges/0.0.x_dev/tests_Windows_3.10.svg
    :target: https://github.com/PyMoDAQ/pymodaq_utils/actions/workflows/tests.yml

.. |311-windows| image:: https://raw.githubusercontent.com/PyMoDAQ/pymodaq_utils/badges/0.0.x_dev/tests_Windows_3.11.svg
    :target: https://github.com/PyMoDAQ/pymodaq_utils/actions/workflows/tests.yml

.. |312-windows| image:: https://raw.githubusercontent.com/PyMoDAQ/pymodaq_utils/badges/0.0.x_dev/tests_Windows_3.12.svg
    :target: https://github.com/PyMoDAQ/pymodaq_utils/actions/workflows/tests.yml





.. figure:: http://pymodaq.cnrs.fr/en/latest/_static/splash.png
   :alt: shortcut


PyMoDAQ__, Modular Data Acquisition with Python, is a set of **python** modules used to interface any kind of
experiments. It simplifies the interaction with detector and actuator hardware to go straight to the data acquisition
of interest.

__ https://pymodaq.readthedocs.io/en/stable/?badge=latest

This present repository `pymodaq_utils` is a set of utilities (constants, methods and classes) that are used in the
various subpackages of PyMoDAQ (PyMoDAQ itself, but also plugins and data management and user interfaces modules)

PyMoDAQ Diagram:

.. figure:: http://pymodaq.cnrs.fr/en/latest/_images/pymodaq_diagram.png
   :alt: overview

   PyMoDAQ's Dashboard and its extensions: DAQ_Scan for automated acquisitions, DAQ_Logger for data logging and many other.


Published under the MIT FREE SOFTWARE LICENSE

GitHub repo: https://github.com/PyMoDAQ

Documentation: http://pymodaq.cnrs.fr/
</file>

<file path="readthedocs.yml">
# .readthedocs.yml
# Read the Docs configuration file
# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details

# Required
version: 2

build:
  os: "ubuntu-22.04"
  tools:
    python: "3.8"


# Build documentation in the docs/ directory with Sphinx
sphinx:
  configuration: docs/src/conf.py


# Optionally build your docs in additional formats such as PDF and ePub
formats: all

# Optionally set the version of Python and requirements required to build your docs
python:
  install:
    - requirements: docs/requirements.txt
    - method: pip
      path: .
</file>

</files>
